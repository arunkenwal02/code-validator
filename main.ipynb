{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac416dc",
   "metadata": {},
   "source": [
    "## Check Docs Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e18532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import nbformat\n",
    "import streamlit as st\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Load White Paper  (PDF)  \n",
    "2. Vectors Embeddings - Text and tables; later include images\n",
    "3. Chroma db\n",
    "4. Retrival - (Accuracy)\n",
    "5. Generation - \n",
    "    Validation-\n",
    "        Data sources - List all sources and metadata\n",
    "        Features - detect any change in features\n",
    "        Changes in Transformation steps\n",
    "        Model Details \n",
    "        Hyperparameter\n",
    "        List of Validation Metrics and resepctive scores\n",
    "        Compare Validation scores of white paper with model's validation scores\n",
    "        Brief of comparision of scores\n",
    "\n",
    "        List and Track of critical metrics - these should not be lower than mentioned (in white paper)\n",
    "\n",
    "6. Respective scores for tracked metrics (confidence on generation)\n",
    "7. If required update prompt and go back to step 4 and reiterate step 4 and 5. reason (geneation have \n",
    "   heiger confidence )\n",
    "8. Outout should be in structured format (This will be input for summary block with affitional 2 inputs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1358c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\",  \n",
    "                 temperature=0,\n",
    "                 openai_api_key= openai_api_key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f30bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_notebook(file_path):\n",
    "    \"\"\"Read .ipynb notebook and extract content.\"\"\"\n",
    "    nb = nbformat.read(file_path, as_version=4)\n",
    "    content = []\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            content.append(\"## Markdown Cell:\\n\" + cell.source)\n",
    "        elif cell.cell_type == 'code':\n",
    "            content.append(\"## Code Cell:\\n```python\\n\" + cell.source + \"\\n```\")\n",
    "    return \"\\n\\n\".join(content)\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"Reads the content of a file.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def extract_functionalities_from_code(notebook_content):\n",
    "\n",
    "    \"\"\"Uses LLM to extract functionalities from Python code.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert Python code reviewer. Here is a Jupyter notebook:\n",
    "    {notebook_content}\n",
    "\n",
    "    The following is a Jupyter notebook content (code and markdown). \n",
    "    Please extract the following:\n",
    "    Analyze the notebook and answer:\n",
    "\n",
    "    1. List of features used in the model.\n",
    "    2. Name/type of ML model used, only name of model\n",
    "    3. Accuracy metrics (e.g., accuracy, F1, precision, recall, AUC, etc.), only metrics name. \n",
    "    4. What is the purpose of this notebook?\n",
    "    5. What are the main operations and their results?\n",
    "    6. Are there any errors or anomalies in outputs?\n",
    "    7. What conclusions can be drawn from the outputs?\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([SystemMessage(content=\"You are a helpful assistant.\"), HumanMessage(content=prompt)])\n",
    "\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "def extract_functionalities_from_whitepaper(whitepaper_text):\n",
    "    \"\"\"Uses LLM to extract functionalities from whitepaper.\"\"\"\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"You are a product analyst.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Here is the whitepaper or product requirement document:\n",
    "\n",
    "        {whitepaper_text}\n",
    "\n",
    "        List all functionalities or features the whitepaper mentions. Use bullet points.\n",
    "        \"\"\")\n",
    "            ]\n",
    "    return llm(prompt).content.strip()\n",
    "\n",
    "\n",
    "def compare_functionalities(whitepaper_funcs, code_funcs):\n",
    "    \"\"\"Compares two sets of functionalities using the LLM.\"\"\"\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"You are a software QA expert.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Whitepaper Functionalities:\n",
    "        {whitepaper_funcs}\n",
    "\n",
    "        Code Functionalities:\n",
    "        {code_funcs}\n",
    "        Extract validation metrics from code funcs eg, precision, recall and other validation are in output cell.\n",
    "        Compare the two lists and identify which functionalities from the whitepape, if functionality is implemented in code but not available in white paper, print: white paper is not updated please update the document. and show details of each section \n",
    "        listmissing sections like feature and if model varies according to white paper and same for validation metrics.\n",
    "        compare validation scores : Compare scores of code function with white paper.\n",
    "        Also compare critical validation metrics: make sure critical metrics of code should be grater then white paper critical metrics\n",
    "        if thereis no changhe in metrics of docuemt and code_funcs: keep output 'white paper is updated please proceed to next steps. no other information is required'  \n",
    "        \n",
    "        \"\"\")\n",
    "            ]\n",
    "    return llm(prompt).content.strip()\n",
    "\n",
    "\n",
    "def read_notebook_with_outputs(file_path):\n",
    "    \"\"\"Read .ipynb notebook and include both code and output.\"\"\"\n",
    "    nb = nbformat.read(file_path, as_version=4)\n",
    "    cells_content = []\n",
    "\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            cells_content.append(f\"## Markdown Cell:\\n{cell.source}\")\n",
    "        elif cell.cell_type == 'code':\n",
    "            code = f\"## Code Cell:\\n```python\\n{cell.source}\\n```\"\n",
    "            outputs = []\n",
    "\n",
    "            for output in cell.get(\"outputs\", []):\n",
    "                if output.output_type == \"stream\":\n",
    "                    outputs.append(f\"Output (stream):\\n{output.text}\")\n",
    "                elif output.output_type == \"execute_result\":\n",
    "                    # Display the result of the cell (e.g., print(2+2))\n",
    "                    result = output.get(\"data\", {}).get(\"text/plain\", \"\")\n",
    "                    outputs.append(f\"Output (execute_result):\\n{result}\")\n",
    "                elif output.output_type == \"error\":\n",
    "                    outputs.append(\"Error:\\n\" + \"\\n\".join(output.get(\"traceback\", [])))\n",
    "\n",
    "            full_output = \"\\n\".join(outputs)\n",
    "            if full_output:\n",
    "                code += f\"\\n\\n### Output:\\n```\\n{full_output}\\n```\"\n",
    "            cells_content.append(code)\n",
    "\n",
    "    return \"\\n\\n\".join(cells_content)\n",
    "\n",
    "def read_notebook(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return nbformat.read(f, as_version=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcfe8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Functionality Coverage Checker\", layout=\"wide\")\n",
    "    \n",
    "    st.title(\"ðŸ§  AI Feature Mapping Validator\")\n",
    "    st.subheader(\"Compare functionalities between a Whitepaper and its Codebase\")\n",
    "\n",
    "    uploaded_whitepaper = st.file_uploader(\"ðŸ“„ Upload Whitepaper File\", type=[\"txt\", \"md\", \"pdf\"])\n",
    "    uploaded_code = st.file_uploader(\"ðŸ’» Upload Code File\", type=[\"py\", \"txt\", \"ipynb\"])\n",
    "\n",
    "    if uploaded_whitepaper and uploaded_code:\n",
    "        if st.button(\"Click to Process Files\"):\n",
    "            # Read whitepaper content\n",
    "            whitepaper = uploaded_whitepaper.read().decode(\"utf-8\")\n",
    "\n",
    "            # Handle .ipynb or other code files\n",
    "            if uploaded_code.name.endswith(\".ipynb\"):\n",
    "                # Write the raw content to a temp file\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=\".ipynb\", mode='wb') as tmp_file:\n",
    "                    tmp_file.write(uploaded_code.read())\n",
    "                    temp_file_path = tmp_file.name\n",
    "\n",
    "                # notebook_contents = read_notebook(temp_file_path)\n",
    "                notebook_contents = read_notebook_with_outputs(temp_file_path)\n",
    "                code_funcs = extract_functionalities_from_code(notebook_contents)\n",
    "            else:\n",
    "                code = uploaded_code.read().decode(\"utf-8\")\n",
    "                code_funcs = extract_functionalities_from_code(code)\n",
    "\n",
    "            whitepaper_funcs = extract_functionalities_from_whitepaper(whitepaper)\n",
    "\n",
    "            st.markdown(\"### âš–ï¸ Comparing Functionalities\")\n",
    "            missing_funcs = compare_functionalities(whitepaper_funcs, code_funcs)\n",
    "            st.markdown(missing_funcs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c540a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f7a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1b071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c25394f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import nbformat\n",
    "# from openai import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.schema import SystemMessage, HumanMessage\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.schema import SystemMessage, HumanMessage\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "\n",
    "# import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries = [\n",
    "#             \"Summary/Objective of white paper \",\n",
    "#             \"Features mentioned\",\n",
    "#             \"Preprocessing steps and data transformation steps\",\n",
    "#             \"Model selected for classification\",\n",
    "#             \"Training and resting methodology\",\n",
    "#             \"List of Hyper parameters and respective values\",\n",
    "#             \"What are list of validation scores and the performance scores?\",\n",
    "#             \"Ethical considerations\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryFun(query, embedding_model,collection):\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    l_docs = []\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=5)\n",
    "    for doc in results[\"documents\"][0]:\n",
    "        l_docs.append(doc)\n",
    "        # print(\"ðŸ”Ž Match:\", l_docs.append(doc))\n",
    "    return l_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81786eca",
   "metadata": {},
   "source": [
    "##  Check Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4fc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb import PersistentClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ab5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./chroma_openai1\"\n",
    "\n",
    "# Step 1: Load the persistent client\n",
    "chroma_client = PersistentClient(path=path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ed8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = chroma_client.list_collections()\n",
    "for col in collections:\n",
    "    print(col.name)\n",
    "    # print(col.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e06b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"notebook_f887cf79f48bf8b101631e9ebdb3ca7220bd2c6e47a6b82041ca192aa98cf16b\"\n",
    "# Step 2: Access the existing collection\n",
    "collection = chroma_client.get_collection(name=collection_name)\n",
    "data = collection.get()\n",
    "\n",
    "# Optional: View details\n",
    "print(\"IDs:\", data['ids'])\n",
    "print(\"Documents:\", data['documents'][:2])  # print only first 2 docs\n",
    "print(\"Metadata:\", data.get('metadatas'))  # only if metadata was stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418da824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: View details\n",
    "print(\"IDs:\", data['ids'])\n",
    "print(\"Documents:\", data['documents'][:2])  # print only first 2 docs\n",
    "print(\"Metadata:\", data.get('metadatas'))  # only if metadata was stored\n",
    "print(\"Embeddings:\", data['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211070c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279493b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ac37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection(\"whitepaper_02958f41437b5bbcf9490a38b0edb5d41a365101ce7979d2822648a320dfdc73\")\n",
    "\n",
    "results = collections[6].get(\n",
    "    ids=[\"id1\", \"id2\"],    # optional\n",
    "    where={\"type\": \"pdf\"}, # optional\n",
    "    include=[\"documents\", \"metadatas\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63925d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Embedding stored or not \n",
    "import os\n",
    "import nbformat\n",
    "from openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "import streamlit as st\n",
    "import fitz\n",
    "import tempfile\n",
    "import hashlib\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_key=openai_api_key)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_hash(uploaded_file):\n",
    "    uploaded_file.seek(0)\n",
    "    hash_val = hashlib.sha256(uploaded_file.read()).hexdigest()\n",
    "    uploaded_file.seek(0)\n",
    "    return hash_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85886d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_pdf(uploaded_file):\n",
    "    doc = fitz.open(stream=uploaded_file.read(), filetype=\"pdf\")\n",
    "    extracted_text = \"\"\n",
    "    for page_num, page in enumerate(doc):\n",
    "        text = page.get_text()\n",
    "        extracted_text += f\"\\n\\n--- Page {page_num + 1} ---\\n{text}\"\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bf1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collection_exists(collection_name):\n",
    "    try:\n",
    "        chroma_client.get_collection(collection_name)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=750,     # faster, smaller chunk\n",
    "        chunk_overlap=100   # reduced overlap\n",
    "    )\n",
    "    return text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_or_create_embeddings(uploaded_file, text, _embedding_model, collection_name):\n",
    "    chunks = create_chunks(text)\n",
    "\n",
    "    if collection_exists(collection_name):\n",
    "        collection = chroma_client.get_collection(collection_name)\n",
    "    else:\n",
    "        embeddings = _embedding_model.embed_documents(chunks)\n",
    "        print(embeddings)\n",
    "        collection = store_in_chromaDB(chunks, embeddings, collection_name)\n",
    "\n",
    "    return collection, chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad320aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import fitz\n",
    "\n",
    "def get_file_hash(file_obj):\n",
    "    file_obj.seek(0)\n",
    "    hash_val = hashlib.sha256(file_obj.read()).hexdigest()\n",
    "    file_obj.seek(0)\n",
    "    return hash_val\n",
    "\n",
    "def extract_from_pdf(file_obj):\n",
    "    file_obj.seek(0)\n",
    "    doc = fitz.open(stream=file_obj.read(), filetype=\"pdf\")\n",
    "    extracted_text = \"\"\n",
    "    for page_num, page in enumerate(doc):\n",
    "        text = page.get_text()\n",
    "        extracted_text += f\"\\n\\n--- Page {page_num + 1} ---\\n{text}\"\n",
    "    return extracted_text\n",
    "\n",
    "file_path = \"Load Prediction Whitepaper.pdf\"\n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    # 1. Compute hash\n",
    "    file_hash = get_file_hash(f)\n",
    "    # 2. Extract text\n",
    "    text = extract_from_pdf(f)\n",
    "    # 3. If needed, reset pointer for further use (not always needed)\n",
    "    f.seek(0)\n",
    "    # 4. Pass to embedding function (if needed)\n",
    "    collection, chunks = get_or_create_embeddings(\n",
    "        uploaded_file=f,              # If function needs file object\n",
    "        text=text,                    # If function needs text\n",
    "        _embedding_model=embedding_model,\n",
    "        collection_name=f\"whitepaper_{file_hash}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec64fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_of_events():\n",
    "    # with open(\"push_events.json\", \"r\") as file:\n",
    "    #     data = json.load(file)\n",
    "    # owner = data[2]\n",
    "    # repo_name = data[3]\n",
    "    api_url = f\"https://api.github.com/repos/arunkenwal02/code-validator/events\"\n",
    "    response = requests.get(api_url)\n",
    "    events = response.json()\n",
    "    push_ids = [id['id'] for id in events]\n",
    "    print(push_ids)\n",
    "    data = ['52949273211','52821120274']\n",
    "    push_events = [e for e in events if e['type'] == 'PushEvent']\n",
    "\n",
    "    ids = [e['id'] for e in push_events]\n",
    "    try:\n",
    "        idx1 = ids.index(data[0])\n",
    "        idx2 = ids.index(data[1])\n",
    "    except ValueError:\n",
    "        return {\"error\": \"One or both push IDs not found in recent events.\"}\n",
    "\n",
    "    start = min(idx1, idx2)\n",
    "    end = max(idx1, idx2)\n",
    "\n",
    "    history_between = push_events[start:end+1]  \n",
    "    grouped_push_events = []\n",
    "    commits_list = []\n",
    "    for event in history_between:\n",
    "        push_id = event['id']\n",
    "        created_at = event['created_at']\n",
    "        repo = event['repo']['name']\n",
    "        commits_list = []\n",
    "\n",
    "        for commit in event[\"payload\"][\"commits\"]:\n",
    "            sha = commit['sha']\n",
    "            author = commit['author']['name']\n",
    "            message = commit['message']\n",
    "\n",
    "            commit_detail_url = f\"https://api.github.com/repos/arunkenwal02/code-validator/commits/{sha}\"\n",
    "            commit_detail_response = requests.get(commit_detail_url)\n",
    "\n",
    "            if commit_detail_response.status_code != 200:\n",
    "                diff = \"âŒ Failed to fetch diff\"\n",
    "            else:\n",
    "                commit_detail = commit_detail_response.json()\n",
    "                diffs = []\n",
    "                for file in commit_detail.get('files', []):\n",
    "                    patch = file.get('patch')\n",
    "                    if patch:\n",
    "                        diffs.append(f\"File: {file['filename']}\\n{patch}\")\n",
    "                diff = \"\\n\\n\".join(diffs) if diffs else \"No diff available\"\n",
    "\n",
    "            commits_list.append({\n",
    "                \"sha\": sha,\n",
    "                \"author\": author,\n",
    "                \"commit_message\": message,\n",
    "                \"code_diff\": diff\n",
    "            })\n",
    "\n",
    "        grouped_push_events.append({\n",
    "            \"push_id\": push_id,\n",
    "            \"repo\": repo,\n",
    "            \"created_at\": created_at,\n",
    "            \"commits\": commits_list\n",
    "        })\n",
    "    return grouped_push_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfe6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_summary_of_events()\n",
    "test\n",
    "push id , commit summary, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a64e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499acb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3313b",
   "metadata": {},
   "source": [
    "## One drive file access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacde4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msal\n",
    "import requests\n",
    "import time\n",
    "import fitz\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "Permission_ID =\"6a94cb3a-9869-4b54-ae0b-f4f523df2614\"\n",
    "client_id = Permission_ID\n",
    "authority = \"https://login.microsoftonline.com/consumers\"\n",
    "scopes = [\"Files.Read\"]\n",
    "source_folder = \"Documents/GitHub/code-validator/\"\n",
    "file_name = \"Load Prediction Whitepaper.pdf\"\n",
    "version_id = int(7)\n",
    "file_path = source_folder+file_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract updated version \n",
    "\n",
    "def access_token_key(client_id, authority):\n",
    "    scopes = [\"Files.Read\"]\n",
    "    app = msal.PublicClientApplication(client_id=client_id, authority=authority)\n",
    "    result = None\n",
    "\n",
    "    accounts = app.get_accounts()\n",
    "    if accounts:\n",
    "        result = app.acquire_token_silent(scopes, account=accounts[0])\n",
    "    if not result:\n",
    "        result = app.acquire_token_interactive(scopes=scopes)\n",
    "    if not result or \"access_token\" not in result:\n",
    "        print(\"MSAL Error:\", result)\n",
    "    access_token = result[\"access_token\"]\n",
    "\n",
    "    return access_token\n",
    "\n",
    "def get_raw_data(client_id, authority ,file_path ):\n",
    "    access_token= access_token_key(client_id=client_id, authority=authority)\n",
    "    url = f\"https://graph.microsoft.com/v1.0/me/drive/root:/{file_path}:/content\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    time.sleep(2)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(f\"Response code: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        file_bytes = response.content\n",
    "        print(\"File read into memory!\")\n",
    "        return file_bytes\n",
    "    else:\n",
    "        print(\"Failed:\", response.status_code, response.text)\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_onedrive_whitepaper(file_bytes):\n",
    "    \n",
    "    # file_bytes is from above\n",
    "    doc = fitz.open(stream=file_bytes, filetype=\"pdf\")\n",
    "    text = \"\"\n",
    "    for page_num, page in enumerate(doc):\n",
    "        text += f\"\\n\\n--- Page {page_num + 1} ---\\n{page.get_text()}\"\n",
    "\n",
    "    print(\"First 1000 chars of PDF text:\", text)\n",
    "    \n",
    "    return text\n",
    "   \n",
    "def prev_version( client_id, authority, file_path, version_id):\n",
    "    access_token= access_token_key(client_id=client_id, authority=authority)\n",
    "\n",
    "    versions_url = f\"https://graph.microsoft.com/v1.0/me/drive/root:/{file_path}:/versions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    response = requests.get(versions_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        versions = response.json()[\"value\"]\n",
    "        if len(versions) >= int(version_id):\n",
    "            # 3. Get the 2nd version (index 1)\n",
    "            version_id = versions[1]['id']\n",
    "            print(f\"2nd Version ID: {version_id}, Last Modified: {versions[1]['lastModifiedDateTime']}\")\n",
    "            \n",
    "            # 4. Fetch 2nd version's PDF bytes\n",
    "            download_url = f\"https://graph.microsoft.com/v1.0/me/drive/root:/{file_path}:/versions/{version_id}/content\"\n",
    "            version_response = requests.get(download_url, headers=headers)\n",
    "            if version_response.status_code == 200:\n",
    "                pdf_bytes = version_response.content  # This is your PDF in memory\n",
    "                \n",
    "                # 5. Extract text from the PDF (in memory, no save)\n",
    "                doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
    "                all_text = \"\"\n",
    "                for page_num, page in enumerate(doc):\n",
    "                    all_text += f\"\\n--- Page {page_num+1} ---\\n{page.get_text()}\"\n",
    "                \n",
    "                print(\"Extracted PDF text (first 1000 chars):\")\n",
    "                print(all_text[:1000])\n",
    "                return all_text\n",
    "                # You can use `all_text` as needed (search, LLM input, etc)\n",
    "            else:\n",
    "                print(\"Failed to download 2nd version:\", version_response.status_code, version_response.text)\n",
    "        else:\n",
    "            print(\"Less than 2 versions available!\")\n",
    "    else:\n",
    "        print(\"Failed to fetch versions:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bc5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_bytes  = get_raw_data(client_id=client_id, authority=authority,file_path = file_path)\n",
    "pdf_content = get_onedrive_whitepaper(file_bytes)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "version_id = 1\n",
    "prev_version(client_id=client_id, authority=authority,  file_path= file_path, version_id = version_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ed6a9",
   "metadata": {},
   "source": [
    "## Get updated file from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e5ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "import requests\n",
    "import requests\n",
    "import base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb8bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_event= pd.read_json('push_events.json', )\n",
    "latest_push_id = push_event[0].tolist()[0]\n",
    "latest_push_id\n",
    "\n",
    "# --- Usage ---\n",
    "owner = \"arunkenwal02\"\n",
    "repo = \"code-validator\"\n",
    "push_id = latest_push_id\n",
    "file_path = \"loan-approval-prediction_v2.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sha_pair_from_push_id(owner, repo, push_id):\n",
    "    \"\"\"\n",
    "    Returns (before_sha, head_sha) for the given push_id.\n",
    "    If not found, returns (None, None).\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/events\"\n",
    "    resp = requests.get(url)\n",
    "    events = resp.json()\n",
    "    for event in events:\n",
    "        if event[\"type\"] == \"PushEvent\" and event[\"id\"] == str(push_id):\n",
    "            before_sha = event[\"payload\"][\"before\"]\n",
    "            head_sha = event[\"payload\"][\"head\"]\n",
    "            print(f\"Push ID: {push_id}\\nbefore: {before_sha}\\nhead: {head_sha}\")\n",
    "            return before_sha, head_sha\n",
    "    print(f\"Push ID {push_id} not found in recent events.\")\n",
    "    return None, None\n",
    "\n",
    "def fetch_latest_file_for_sha(owner, repo, file_path, sha_pairs):\n",
    "    \"\"\"\n",
    "    For each (sha_old, sha_new) in sha_pairs, check if file_path was updated.\n",
    "    If yes, download file from sha_new. Else, download most recently updated version.\n",
    "    \"\"\"\n",
    "    for i, (sha_old, sha_new) in enumerate(sha_pairs):\n",
    "        print(f\"\\nProcessing pair {i+1}: {sha_old} â†’ {sha_new}\")\n",
    "\n",
    "        # 1. Compare the two SHAs\n",
    "        compare_url = f\"https://api.github.com/repos/{owner}/{repo}/compare/{sha_old}...{sha_new}\"\n",
    "        compare_resp = requests.get(compare_url)\n",
    "        compare_data = compare_resp.json()\n",
    "\n",
    "        file_changed = False\n",
    "        for f in compare_data.get(\"files\", []):\n",
    "            if f[\"filename\"] == file_path:\n",
    "                file_changed = True\n",
    "                print(f\"File {file_path} was changed in this push.\")\n",
    "                break\n",
    "\n",
    "        if file_changed:\n",
    "            # Download updated file from sha_new\n",
    "            content_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{file_path}\"\n",
    "            params = {\"ref\": sha_new}\n",
    "            file_resp = requests.get(content_url, params=params)\n",
    "            file_data = file_resp.json()\n",
    "            \n",
    "        # Check for 'content' key (base64-encoded)\n",
    "            if \"content\" in file_data:\n",
    "                nb_json = base64.b64decode(file_data[\"content\"]).decode(\"utf-8\")\n",
    "                notebook_dict = json.loads(nb_json)\n",
    "                return notebook_dict\n",
    "            else:\n",
    "                raise Exception(\"Notebook not found or could not fetch content. Details: \" + str(file_data))\n",
    "\n",
    "        else:\n",
    "            print(f\"File {file_path} was NOT changed between {sha_old} and {sha_new}.\")\n",
    "            # Get most recent commit where this file was updated\n",
    "            commits_url = f\"https://api.github.com/repos/{owner}/{repo}/commits\"\n",
    "            params = {\"path\": file_path, \"per_page\": 1}\n",
    "            commits_resp = requests.get(commits_url, params=params)\n",
    "            last_update_sha = commits_resp.json()[0][\"sha\"]\n",
    "            print(\"Most recent commit where file was changed:\", last_update_sha)\n",
    "            # Download file at that SHA\n",
    "            content_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{file_path}\"\n",
    "            params = {\"ref\": last_update_sha}\n",
    "            file_resp = requests.get(content_url, params=params)\n",
    "            file_data = file_resp.json()\n",
    "            \n",
    "            # Check for 'content' key (base64-encoded)\n",
    "            if \"content\" in file_data:\n",
    "                nb_json = base64.b64decode(file_data[\"content\"]).decode(\"utf-8\")\n",
    "                notebook_dict = json.loads(nb_json)\n",
    "                return notebook_dict\n",
    "            else:\n",
    "                raise Exception(\"Notebook not found or could not fetch content. Details: \" + str(file_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5518dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push ID: 52764657352\n",
      "before: a92475d2557a2d1dd1e17c0a2f57ff950d60b6ae\n",
      "head: 057c3593f00d2b21d20d4b572095038807df5de1\n",
      "\n",
      "Processing pair 1: a92475d2557a2d1dd1e17c0a2f57ff950d60b6ae â†’ 057c3593f00d2b21d20d4b572095038807df5de1\n",
      "File loan-approval-prediction_v2.ipynb was NOT changed between a92475d2557a2d1dd1e17c0a2f57ff950d60b6ae and 057c3593f00d2b21d20d4b572095038807df5de1.\n",
      "Most recent commit where file was changed: 899191ec55d9a7d44bcdaed22e41395f946059df\n"
     ]
    }
   ],
   "source": [
    "sha_pair = get_sha_pair_from_push_id(owner, repo, push_id)\n",
    "\n",
    "sha_pair = [sha_pair]\n",
    "fetch_latest_file_for_sha \n",
    "# --- Usage example ---\n",
    "notebook_contents = fetch_latest_file_for_sha(owner, repo, file_path, sha_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "befb97bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cell #11:\n",
      "Code:\n",
      "# Data dimension\n",
      "print('Data dimension: {} rows and {} columns'.format(len(df_train), len(df_train.columns)))\n",
      "df_train.head()\n",
      "\n",
      "Outputs:\n",
      "Data dimension: 491 rows and 13 columns\n",
      "\n",
      "Data dimension: 491 rows and 13 columns\n",
      "\n",
      "['    Loan_ID  Gender Married Dependents     Education Self_Employed  \\\\\\n', '0  LP002305  Female      No          0      Graduate            No   \\n', '1  LP001715    Male     Yes         3+  Not Graduate           Yes   \\n', '2  LP002086  Female     Yes          0      Graduate            No   \\n', '3  LP001136    Male     Yes          0  Not Graduate           Yes   \\n', '4  LP002529    Male     Yes          2      Graduate            No   \\n', '\\n', '   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\\\\n', '0             4547                0.0       115.0             360.0   \\n', '1             5703                0.0       130.0             360.0   \\n', '2             4333             2451.0       110.0             360.0   \\n', '3             4695                0.0        96.0               NaN   \\n', '4             6700             1750.0       230.0             300.0   \\n', '\\n', '   Credit_History Property_Area  Loan_Status  \\n', '0             1.0     Semiurban            1  \\n', '1             1.0         Rural            1  \\n', '2             1.0         Urban            0  \\n', '3             1.0         Urban            1  \\n', '4             1.0     Semiurban            1  ']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Loan_ID</th>\\n', '      <th>Gender</th>\\n', '      <th>Married</th>\\n', '      <th>Dependents</th>\\n', '      <th>Education</th>\\n', '      <th>Self_Employed</th>\\n', '      <th>ApplicantIncome</th>\\n', '      <th>CoapplicantIncome</th>\\n', '      <th>LoanAmount</th>\\n', '      <th>Loan_Amount_Term</th>\\n', '      <th>Credit_History</th>\\n', '      <th>Property_Area</th>\\n', '      <th>Loan_Status</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>LP002305</td>\\n', '      <td>Female</td>\\n', '      <td>No</td>\\n', '      <td>0</td>\\n', '      <td>Graduate</td>\\n', '      <td>No</td>\\n', '      <td>4547</td>\\n', '      <td>0.0</td>\\n', '      <td>115.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1.0</td>\\n', '      <td>Semiurban</td>\\n', '      <td>1</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>LP001715</td>\\n', '      <td>Male</td>\\n', '      <td>Yes</td>\\n', '      <td>3+</td>\\n', '      <td>Not Graduate</td>\\n', '      <td>Yes</td>\\n', '      <td>5703</td>\\n', '      <td>0.0</td>\\n', '      <td>130.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1.0</td>\\n', '      <td>Rural</td>\\n', '      <td>1</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>LP002086</td>\\n', '      <td>Female</td>\\n', '      <td>Yes</td>\\n', '      <td>0</td>\\n', '      <td>Graduate</td>\\n', '      <td>No</td>\\n', '      <td>4333</td>\\n', '      <td>2451.0</td>\\n', '      <td>110.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1.0</td>\\n', '      <td>Urban</td>\\n', '      <td>0</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>LP001136</td>\\n', '      <td>Male</td>\\n', '      <td>Yes</td>\\n', '      <td>0</td>\\n', '      <td>Not Graduate</td>\\n', '      <td>Yes</td>\\n', '      <td>4695</td>\\n', '      <td>0.0</td>\\n', '      <td>96.0</td>\\n', '      <td>NaN</td>\\n', '      <td>1.0</td>\\n', '      <td>Urban</td>\\n', '      <td>1</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>4</th>\\n', '      <td>LP002529</td>\\n', '      <td>Male</td>\\n', '      <td>Yes</td>\\n', '      <td>2</td>\\n', '      <td>Graduate</td>\\n', '      <td>No</td>\\n', '      <td>6700</td>\\n', '      <td>1750.0</td>\\n', '      <td>230.0</td>\\n', '      <td>300.0</td>\\n', '      <td>1.0</td>\\n', '      <td>Semiurban</td>\\n', '      <td>1</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #14:\n",
      "Code:\n",
      "# Data dimension\n",
      "print('Data dimension: {} rows and {} columns'.format(len(df_test), len(df_test.columns)))\n",
      "df_test.head()\n",
      "\n",
      "Outputs:\n",
      "Data dimension: 123 rows and 12 columns\n",
      "\n",
      "Data dimension: 123 rows and 12 columns\n",
      "\n",
      "['    Loan_ID Gender Married Dependents     Education Self_Employed  \\\\\\n', '0  LP001116   Male      No          0  Not Graduate            No   \\n', '1  LP001488   Male     Yes         3+      Graduate            No   \\n', '2  LP002138   Male     Yes          0      Graduate            No   \\n', '3  LP002284   Male      No          0  Not Graduate            No   \\n', '4  LP002328   Male     Yes          0  Not Graduate            No   \\n', '\\n', '   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\\\\n', '0             3748             1668.0       110.0             360.0   \\n', '1             4000             7750.0       290.0             360.0   \\n', '2             2625             6250.0       187.0             360.0   \\n', '3             3902             1666.0       109.0             360.0   \\n', '4             6096                0.0       218.0             360.0   \\n', '\\n', '   Credit_History Property_Area  \\n', '0             1.0     Semiurban  \\n', '1             1.0     Semiurban  \\n', '2             1.0         Rural  \\n', '3             1.0         Rural  \\n', '4             0.0         Rural  ']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Loan_ID</th>\\n', '      <th>Gender</th>\\n', '      <th>Married</th>\\n', '      <th>Dependents</th>\\n', '      <th>Education</th>\\n', '      <th>Self_Employed</th>\\n', '      <th>ApplicantIncome</th>\\n', '      <th>CoapplicantIncome</th>\\n', '      <th>LoanAmount</th>\\n', '      <th>Loan_Amount_Term</th>\\n', '      <th>Credit_History</th>\\n', '      <th>Property_Area</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>LP001116</td>\\n', '      <td>Male</td>\\n', '      <td>No</td>\\n', '      <td>0</td>\\n', '      <td>Not Graduate</td>\\n', '      <td>No</td>\\n', '      <td>3748</td>\\n', '      <td>1668.0</td>\\n', '      <td>110.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1.0</td>\\n', '      <td>Semiurban</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>LP001488</td>\\n', '      <td>Male</td>\\n', '      <td>Yes</td>\\n', '      <td>3+</td>\\n', '      <td>Graduate</td>\\n', '      <td>No</td>\\n', '      <td>4000</td>\\n', '      <td>7750.0</td>\\n', '      <td>290.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1.0</td>\\n', '      <td>Semiurban</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>LP002138</td>\\n', '      <td>Male</td>\\n', '      <td>Yes</td>\\n', '      <td>0</td>\\n', '      <td>Graduate</td>\\n', '      <td>No</td>\\n', '      <td>2625</td>\\n', '      <td>6250.0</td>\\n', '      <td>187.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1.0</td>\\n', '      <td>Rural</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>LP002284</td>\\n', '      <td>Male</td>\\n', '      <td>No</td>\\n', '      <td>0</td>\\n', '      <td>Not Graduate</td>\\n', '      <td>No</td>\\n', '      <td>3902</td>\\n', '      <td>1666.0</td>\\n', '      <td>109.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1.0</td>\\n', '      <td>Rural</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>4</th>\\n', '      <td>LP002328</td>\\n', '      <td>Male</td>\\n', '      <td>Yes</td>\\n', '      <td>0</td>\\n', '      <td>Not Graduate</td>\\n', '      <td>No</td>\\n', '      <td>6096</td>\\n', '      <td>0.0</td>\\n', '      <td>218.0</td>\\n', '      <td>360.0</td>\\n', '      <td>0.0</td>\\n', '      <td>Rural</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #19:\n",
      "Code:\n",
      "# Data frame metadata\n",
      "df_train.info()\n",
      "\n",
      "Outputs:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 491 entries, 0 to 490\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            491 non-null    object \n",
      " 1   Gender             481 non-null    object \n",
      " 2   Married            490 non-null    object \n",
      " 3   Dependents         482 non-null    object \n",
      " 4   Education          491 non-null    object \n",
      " 5   Self_Employed      462 non-null    object \n",
      " 6   ApplicantIncome    491 non-null    int64  \n",
      " 7   CoapplicantIncome  491 non-null    float64\n",
      " 8   LoanAmount         475 non-null    float64\n",
      " 9   Loan_Amount_Term   478 non-null    float64\n",
      " 10  Credit_History     448 non-null    float64\n",
      " 11  Property_Area      491 non-null    object \n",
      " 12  Loan_Status        491 non-null    int64  \n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 50.0+ KB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 491 entries, 0 to 490\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            491 non-null    object \n",
      " 1   Gender             481 non-null    object \n",
      " 2   Married            490 non-null    object \n",
      " 3   Dependents         482 non-null    object \n",
      " 4   Education          491 non-null    object \n",
      " 5   Self_Employed      462 non-null    object \n",
      " 6   ApplicantIncome    491 non-null    int64  \n",
      " 7   CoapplicantIncome  491 non-null    float64\n",
      " 8   LoanAmount         475 non-null    float64\n",
      " 9   Loan_Amount_Term   478 non-null    float64\n",
      " 10  Credit_History     448 non-null    float64\n",
      " 11  Property_Area      491 non-null    object \n",
      " 12  Loan_Status        491 non-null    int64  \n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 50.0+ KB\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #20:\n",
      "Code:\n",
      "# Change column types\n",
      "df_train = df_train.astype({'Credit_History': object, 'Loan_Status': int})\n",
      "df_train.select_dtypes(include = ['object']).dtypes\n",
      "\n",
      "Outputs:\n",
      "['Loan_ID           object\\n', 'Gender            object\\n', 'Married           object\\n', 'Dependents        object\\n', 'Education         object\\n', 'Self_Employed     object\\n', 'Credit_History    object\\n', 'Property_Area     object\\n', 'dtype: object']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #21:\n",
      "Code:\n",
      "# Summary statistics of categorical columns\n",
      "for i in df_train.select_dtypes('object').columns:\n",
      "    print(df_train[i].value_counts(),'\\n')\n",
      "\n",
      "Outputs:\n",
      "Loan_ID\n",
      "LP002777    1\n",
      "LP002305    1\n",
      "LP001715    1\n",
      "LP002086    1\n",
      "LP001136    1\n",
      "           ..\n",
      "LP002379    1\n",
      "LP001011    1\n",
      "LP001508    1\n",
      "LP001112    1\n",
      "LP002130    1\n",
      "Name: count, Length: 491, dtype: int64 \n",
      "\n",
      "Gender\n",
      "Male      393\n",
      "Female     88\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Married\n",
      "Yes    324\n",
      "No     166\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Dependents\n",
      "0     276\n",
      "1      85\n",
      "2      78\n",
      "3+     43\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Education\n",
      "Graduate        388\n",
      "Not Graduate    103\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Self_Employed\n",
      "No     398\n",
      "Yes     64\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Credit_History\n",
      "1.0    380\n",
      "0.0     68\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Property_Area\n",
      "Semiurban    186\n",
      "Urban        155\n",
      "Rural        150\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "\n",
      "Loan_ID\n",
      "LP002777    1\n",
      "LP002305    1\n",
      "LP001715    1\n",
      "LP002086    1\n",
      "LP001136    1\n",
      "           ..\n",
      "LP002379    1\n",
      "LP001011    1\n",
      "LP001508    1\n",
      "LP001112    1\n",
      "LP002130    1\n",
      "Name: count, Length: 491, dtype: int64 \n",
      "\n",
      "Gender\n",
      "Male      393\n",
      "Female     88\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Married\n",
      "Yes    324\n",
      "No     166\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Dependents\n",
      "0     276\n",
      "1      85\n",
      "2      78\n",
      "3+     43\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Education\n",
      "Graduate        388\n",
      "Not Graduate    103\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Self_Employed\n",
      "No     398\n",
      "Yes     64\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Credit_History\n",
      "1.0    380\n",
      "0.0     68\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Property_Area\n",
      "Semiurban    186\n",
      "Urban        155\n",
      "Rural        150\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #23:\n",
      "Code:\n",
      "# Check missing values\n",
      "df_train.isna().sum()\n",
      "\n",
      "Outputs:\n",
      "['Loan_ID               0\\n', 'Gender               10\\n', 'Married               1\\n', 'Dependents            9\\n', 'Education             0\\n', 'Self_Employed        29\\n', 'ApplicantIncome       0\\n', 'CoapplicantIncome     0\\n', 'LoanAmount           16\\n', 'Loan_Amount_Term     13\\n', 'Credit_History       43\\n', 'Property_Area         0\\n', 'Loan_Status           0\\n', 'dtype: int64']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #26:\n",
      "Code:\n",
      "print('Number of missing dependents is about {} rows'.format(df_train['Dependents'].isna().sum()))\n",
      "\n",
      "Outputs:\n",
      "Number of missing dependents is about 9 rows\n",
      "\n",
      "Number of missing dependents is about 9 rows\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #29:\n",
      "Code:\n",
      "print('Number of missing Self_Employed is about {} rows'.format(df_train['Self_Employed'].isna().sum()))\n",
      "\n",
      "Outputs:\n",
      "Number of missing Self_Employed is about 29 rows\n",
      "\n",
      "Number of missing Self_Employed is about 29 rows\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #32:\n",
      "Code:\n",
      "df_train[['Loan_Amount_Term', 'Loan_Status']].groupby('Loan_Status').describe()\n",
      "\n",
      "Outputs:\n",
      "['            Loan_Amount_Term                                             \\\\\\n', '                       count        mean        std   min    25%    50%   \\n', 'Loan_Status                                                               \\n', '0                      143.0  341.790210  73.018891  36.0  360.0  360.0   \\n', '1                      335.0  341.086567  64.320411  12.0  360.0  360.0   \\n', '\\n', '                           \\n', '               75%    max  \\n', 'Loan_Status                \\n', '0            360.0  480.0  \\n', '1            360.0  480.0  ']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead tr th {\\n', '        text-align: left;\\n', '    }\\n', '\\n', '    .dataframe thead tr:last-of-type th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr>\\n', '      <th></th>\\n', '      <th colspan=\"8\" halign=\"left\">Loan_Amount_Term</th>\\n', '    </tr>\\n', '    <tr>\\n', '      <th></th>\\n', '      <th>count</th>\\n', '      <th>mean</th>\\n', '      <th>std</th>\\n', '      <th>min</th>\\n', '      <th>25%</th>\\n', '      <th>50%</th>\\n', '      <th>75%</th>\\n', '      <th>max</th>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>Loan_Status</th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>143.0</td>\\n', '      <td>341.790210</td>\\n', '      <td>73.018891</td>\\n', '      <td>36.0</td>\\n', '      <td>360.0</td>\\n', '      <td>360.0</td>\\n', '      <td>360.0</td>\\n', '      <td>480.0</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>335.0</td>\\n', '      <td>341.086567</td>\\n', '      <td>64.320411</td>\\n', '      <td>12.0</td>\\n', '      <td>360.0</td>\\n', '      <td>360.0</td>\\n', '      <td>360.0</td>\\n', '      <td>480.0</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #33:\n",
      "Code:\n",
      "print('Percentile 20th: {}'.format(df_train['Loan_Amount_Term'].quantile(q = 0.2)))\n",
      "\n",
      "Outputs:\n",
      "Percentile 20th: 360.0\n",
      "\n",
      "Percentile 20th: 360.0\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #36:\n",
      "Code:\n",
      "# Cross tabulation of credit history and loan status\n",
      "df_cred_hist = pd.crosstab(df_train['Credit_History'], df_train['Loan_Status'], margins = True).reset_index()\n",
      "# Remove index name\n",
      "df_cred_hist.columns.name = None\n",
      "# Remove last row for total column attribute\n",
      "df_cred_hist = df_cred_hist.drop([len(df_cred_hist) - 1], axis = 0)\n",
      "df_cred_hist.rename(columns = {'Credit_History':'Credit History', 0:'No', 1:'Yes'}, inplace = True)\n",
      "df_cred_hist\n",
      "\n",
      "Outputs:\n",
      "['  Credit History  No  Yes  All\\n', '0            0.0  62    6   68\\n', '1            1.0  74  306  380']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Credit History</th>\\n', '      <th>No</th>\\n', '      <th>Yes</th>\\n', '      <th>All</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>0.0</td>\\n', '      <td>62</td>\\n', '      <td>6</td>\\n', '      <td>68</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>1.0</td>\\n', '      <td>74</td>\\n', '      <td>306</td>\\n', '      <td>380</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #37:\n",
      "Code:\n",
      "# Slice the data frame based on loan status\n",
      "pos_cred_hist0 = df_train[(df_train['Credit_History'].isna()) & (df_train['Loan_Status'] == 0)]\n",
      "pos_cred_hist1 = df_train[(df_train['Credit_History'].isna()) & (df_train['Loan_Status'] == 1)]\n",
      "print('Number of rows with Loan_Status is No but Credit_History is NaN  : {}'.format(len(pos_cred_hist0)))\n",
      "print('Number of rows with Loan_Status is Yes but Credit_History is NaN : {}'.format(len(pos_cred_hist1)))\n",
      "\n",
      "Outputs:\n",
      "Number of rows with Loan_Status is No but Credit_History is NaN  : 12\n",
      "Number of rows with Loan_Status is Yes but Credit_History is NaN : 31\n",
      "\n",
      "Number of rows with Loan_Status is No but Credit_History is NaN  : 12\n",
      "Number of rows with Loan_Status is Yes but Credit_History is NaN : 31\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #41:\n",
      "Code:\n",
      "# Check missing value\n",
      "df_train.isna().sum()\n",
      "\n",
      "Outputs:\n",
      "['Loan_ID              0\\n', 'Gender               0\\n', 'Married              0\\n', 'Dependents           0\\n', 'Education            0\\n', 'Self_Employed        0\\n', 'ApplicantIncome      0\\n', 'CoapplicantIncome    0\\n', 'LoanAmount           0\\n', 'Loan_Amount_Term     0\\n', 'Credit_History       0\\n', 'Property_Area        0\\n', 'Loan_Status          0\\n', 'dtype: int64']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #44:\n",
      "Code:\n",
      "# Data frame metadata\n",
      "df_test.info()\n",
      "\n",
      "Outputs:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            123 non-null    object \n",
      " 1   Gender             120 non-null    object \n",
      " 2   Married            121 non-null    object \n",
      " 3   Dependents         117 non-null    object \n",
      " 4   Education          123 non-null    object \n",
      " 5   Self_Employed      120 non-null    object \n",
      " 6   ApplicantIncome    123 non-null    int64  \n",
      " 7   CoapplicantIncome  123 non-null    float64\n",
      " 8   LoanAmount         117 non-null    float64\n",
      " 9   Loan_Amount_Term   122 non-null    float64\n",
      " 10  Credit_History     116 non-null    float64\n",
      " 11  Property_Area      123 non-null    object \n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 11.7+ KB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            123 non-null    object \n",
      " 1   Gender             120 non-null    object \n",
      " 2   Married            121 non-null    object \n",
      " 3   Dependents         117 non-null    object \n",
      " 4   Education          123 non-null    object \n",
      " 5   Self_Employed      120 non-null    object \n",
      " 6   ApplicantIncome    123 non-null    int64  \n",
      " 7   CoapplicantIncome  123 non-null    float64\n",
      " 8   LoanAmount         117 non-null    float64\n",
      " 9   Loan_Amount_Term   122 non-null    float64\n",
      " 10  Credit_History     116 non-null    float64\n",
      " 11  Property_Area      123 non-null    object \n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 11.7+ KB\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #45:\n",
      "Code:\n",
      "# Change column types\n",
      "df_test = df_test.astype({'Credit_History': object})\n",
      "df_test.select_dtypes(include = ['object']).dtypes\n",
      "\n",
      "Outputs:\n",
      "['Loan_ID           object\\n', 'Gender            object\\n', 'Married           object\\n', 'Dependents        object\\n', 'Education         object\\n', 'Self_Employed     object\\n', 'Credit_History    object\\n', 'Property_Area     object\\n', 'dtype: object']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #46:\n",
      "Code:\n",
      "# Summary statistics of categorical columns\n",
      "for i in df_test.select_dtypes('object').columns:\n",
      "    print(df_test[i].value_counts(),'\\n')\n",
      "\n",
      "Outputs:\n",
      "Loan_ID\n",
      "LP001116    1\n",
      "LP001488    1\n",
      "LP002138    1\n",
      "LP002284    1\n",
      "LP002328    1\n",
      "           ..\n",
      "LP002683    1\n",
      "LP002054    1\n",
      "LP002757    1\n",
      "LP002582    1\n",
      "LP001616    1\n",
      "Name: count, Length: 123, dtype: int64 \n",
      "\n",
      "Gender\n",
      "Male      96\n",
      "Female    24\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Married\n",
      "Yes    74\n",
      "No     47\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Dependents\n",
      "0     69\n",
      "2     23\n",
      "1     17\n",
      "3+     8\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Education\n",
      "Graduate        92\n",
      "Not Graduate    31\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Self_Employed\n",
      "No     102\n",
      "Yes     18\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Credit_History\n",
      "1.0    95\n",
      "0.0    21\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Property_Area\n",
      "Semiurban    47\n",
      "Urban        47\n",
      "Rural        29\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "\n",
      "Loan_ID\n",
      "LP001116    1\n",
      "LP001488    1\n",
      "LP002138    1\n",
      "LP002284    1\n",
      "LP002328    1\n",
      "           ..\n",
      "LP002683    1\n",
      "LP002054    1\n",
      "LP002757    1\n",
      "LP002582    1\n",
      "LP001616    1\n",
      "Name: count, Length: 123, dtype: int64 \n",
      "\n",
      "Gender\n",
      "Male      96\n",
      "Female    24\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Married\n",
      "Yes    74\n",
      "No     47\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Dependents\n",
      "0     69\n",
      "2     23\n",
      "1     17\n",
      "3+     8\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Education\n",
      "Graduate        92\n",
      "Not Graduate    31\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Self_Employed\n",
      "No     102\n",
      "Yes     18\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Credit_History\n",
      "1.0    95\n",
      "0.0    21\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Property_Area\n",
      "Semiurban    47\n",
      "Urban        47\n",
      "Rural        29\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #48:\n",
      "Code:\n",
      "# Check missing values\n",
      "df_test.isna().sum()\n",
      "\n",
      "Outputs:\n",
      "['Loan_ID              0\\n', 'Gender               3\\n', 'Married              2\\n', 'Dependents           6\\n', 'Education            0\\n', 'Self_Employed        3\\n', 'ApplicantIncome      0\\n', 'CoapplicantIncome    0\\n', 'LoanAmount           6\\n', 'Loan_Amount_Term     1\\n', 'Credit_History       7\\n', 'Property_Area        0\\n', 'dtype: int64']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #50:\n",
      "Code:\n",
      "print('Number of missing values in Dependents is about {} rows'.format(df_test['Dependents'].isna().sum()))\n",
      "\n",
      "Outputs:\n",
      "Number of missing values in Dependents is about 6 rows\n",
      "\n",
      "Number of missing values in Dependents is about 6 rows\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #53:\n",
      "Code:\n",
      "print('Number of missing values in Self_Employed is about {} rows'.format(df_test['Self_Employed'].isna().sum()))\n",
      "\n",
      "Outputs:\n",
      "Number of missing values in Self_Employed is about 3 rows\n",
      "\n",
      "Number of missing values in Self_Employed is about 3 rows\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #59:\n",
      "Code:\n",
      "# Check missing values\n",
      "df_test.isna().sum()\n",
      "\n",
      "Outputs:\n",
      "['Loan_ID              0\\n', 'Gender               0\\n', 'Married              0\\n', 'Dependents           0\\n', 'Education            0\\n', 'Self_Employed        0\\n', 'ApplicantIncome      0\\n', 'CoapplicantIncome    0\\n', 'LoanAmount           0\\n', 'Loan_Amount_Term     0\\n', 'Credit_History       0\\n', 'Property_Area        0\\n', 'dtype: int64']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #63:\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_1\n",
      "\n",
      "Outputs:\n",
      "['   Loan_Status  Total\\n', '0  Not default    134\\n', '1      Default    330']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Loan_Status</th>\\n', '      <th>Total</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>Not default</td>\\n', '      <td>134</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>Default</td>\\n', '      <td>330</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #64:\n",
      "Code:\n",
      "# Figure size\n",
      "plt.figure(figsize = (6.4,4.8))\n",
      "\n",
      "# Customize colors and other settings\n",
      "colors = ['#80797c','#981220']\n",
      "\n",
      "# Explode 1st slice\n",
      "explode = (0.1, 0)\n",
      "\n",
      "# Create a pie chart\n",
      "plt.pie(\n",
      "    x = 'Total',\n",
      "    labels = 'Loan_Status',\n",
      "    data = df_viz_1,\n",
      "    explode = explode,\n",
      "    colors = colors,\n",
      "    autopct = '%1.1f%%',\n",
      "    shadow = False,\n",
      "    startangle = 140\n",
      ")\n",
      "\n",
      "# Title and axis\n",
      "plt.title('Number of customers by loan status', fontsize = 18)\n",
      "plt.axis('equal')\n",
      "plt.show()\n",
      "\n",
      "Outputs:\n",
      "['<Figure size 640x480 with 1 Axes>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #67:\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_2\n",
      "\n",
      "Outputs:\n",
      "['   Loan_Status Dependents  Total\\n', '0  Not default          0     77\\n', '1  Not default          1     30\\n', '2  Not default          2     13\\n', '3  Not default         3+     14\\n', '4      Default          0    191\\n', '5      Default          1     52\\n', '6      Default          2     62\\n', '7      Default         3+     25']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Loan_Status</th>\\n', '      <th>Dependents</th>\\n', '      <th>Total</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>Not default</td>\\n', '      <td>0</td>\\n', '      <td>77</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>Not default</td>\\n', '      <td>1</td>\\n', '      <td>30</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>Not default</td>\\n', '      <td>2</td>\\n', '      <td>13</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>Not default</td>\\n', '      <td>3+</td>\\n', '      <td>14</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>4</th>\\n', '      <td>Default</td>\\n', '      <td>0</td>\\n', '      <td>191</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>5</th>\\n', '      <td>Default</td>\\n', '      <td>1</td>\\n', '      <td>52</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>6</th>\\n', '      <td>Default</td>\\n', '      <td>2</td>\\n', '      <td>62</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>7</th>\\n', '      <td>Default</td>\\n', '      <td>3+</td>\\n', '      <td>25</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #68:\n",
      "Code:\n",
      "plotnine.options.figure_size = (8, 4.8)\n",
      "(\n",
      "    ggplot(\n",
      "        data = df_viz_2\n",
      "    )+\n",
      "    geom_bar(\n",
      "        aes(\n",
      "            x = 'Dependents',\n",
      "            y = 'Total',\n",
      "            fill = 'Loan_Status'\n",
      "        ),\n",
      "        stat = 'identity',\n",
      "        position = 'fill',\n",
      "        width = 0.5\n",
      "    )+\n",
      "    labs(\n",
      "        title = 'The composition of loan status by the dependents',\n",
      "        fill = 'Loan status'\n",
      "    )+\n",
      "    xlab(\n",
      "        'Dependents'\n",
      "    )+\n",
      "    ylab(\n",
      "        'Frequency'\n",
      "    )+\n",
      "    scale_x_discrete(\n",
      "        limits = ['0', '1', '2', '3+']\n",
      "    )+\n",
      "    scale_fill_manual(\n",
      "        values = ['#981220','#80797c'],\n",
      "        labels = ['Default', 'Not Default']\n",
      "    )+\n",
      "    theme_minimal()\n",
      ")\n",
      "\n",
      "Outputs:\n",
      "----------------------------------------\n",
      "\n",
      "Cell #71:\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_3\n",
      "\n",
      "Outputs:\n",
      "['   Loan_Status     Education  Total\\n', '0  Not default      Graduate    101\\n', '1  Not default  Not Graduate     33\\n', '2      Default      Graduate    266\\n', '3      Default  Not Graduate     64']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Loan_Status</th>\\n', '      <th>Education</th>\\n', '      <th>Total</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>Not default</td>\\n', '      <td>Graduate</td>\\n', '      <td>101</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>Not default</td>\\n', '      <td>Not Graduate</td>\\n', '      <td>33</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>Default</td>\\n', '      <td>Graduate</td>\\n', '      <td>266</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>Default</td>\\n', '      <td>Not Graduate</td>\\n', '      <td>64</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #72:\n",
      "Code:\n",
      "plotnine.options.figure_size = (8, 4.8)\n",
      "(\n",
      "    ggplot(\n",
      "        data = df_viz_3\n",
      "    )+\n",
      "    geom_bar(\n",
      "        aes(\n",
      "            x = 'Education',\n",
      "            y = 'Total',\n",
      "            fill = 'Loan_Status'\n",
      "        ),\n",
      "        stat = 'identity',\n",
      "        position = 'fill',\n",
      "        width = 0.5\n",
      "    )+\n",
      "    labs(\n",
      "        title = 'The composition of loan status by the education',\n",
      "        fill = 'Loan status'\n",
      "    )+\n",
      "    xlab(\n",
      "        'Educations'\n",
      "    )+\n",
      "    ylab(\n",
      "        'Frequency'\n",
      "    )+\n",
      "    scale_x_discrete(\n",
      "        limits = ['Graduate', 'Not Graduate']\n",
      "    )+\n",
      "    scale_fill_manual(\n",
      "        values = ['#981220','#80797c'],\n",
      "        labels = ['Default', 'Not Default']\n",
      "    )+\n",
      "    theme_minimal()\n",
      ")\n",
      "\n",
      "Outputs:\n",
      "----------------------------------------\n",
      "\n",
      "Cell #75:\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_4.head()\n",
      "\n",
      "Outputs:\n",
      "['   ApplicantIncome  Loan_Status\\n', '0             4547      Default\\n', '1             5703      Default\\n', '2             4333  Not default\\n', '3             4695      Default\\n', '4             6700      Default']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>ApplicantIncome</th>\\n', '      <th>Loan_Status</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>4547</td>\\n', '      <td>Default</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>5703</td>\\n', '      <td>Default</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>4333</td>\\n', '      <td>Not default</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>4695</td>\\n', '      <td>Default</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>4</th>\\n', '      <td>6700</td>\\n', '      <td>Default</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #76:\n",
      "Code:\n",
      "plotnine.options.figure_size = (8, 4.8)\n",
      "(\n",
      "    ggplot(\n",
      "        data = df_viz_4\n",
      "    )+\n",
      "    geom_density(\n",
      "        aes(\n",
      "            x = 'ApplicantIncome',\n",
      "            fill = 'Loan_Status'\n",
      "        ),\n",
      "        color = 'white',\n",
      "        alpha = 0.85\n",
      "    )+\n",
      "    labs(\n",
      "        title = 'The distribution of applicant incomes by loan status'\n",
      "    )+\n",
      "    scale_fill_manual(\n",
      "        name = 'Loan Status',\n",
      "        values = ['#981220','#80797c'],\n",
      "        labels = ['Default', 'Not Default']\n",
      "    )+\n",
      "    xlab(\n",
      "        'Applicant income'\n",
      "    )+\n",
      "    ylab(\n",
      "        'Density'\n",
      "    )+\n",
      "    theme_minimal()\n",
      ")\n",
      "\n",
      "Outputs:\n",
      "----------------------------------------\n",
      "\n",
      "Cell #79:\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_5.head()\n",
      "\n",
      "Outputs:\n",
      "['   LoanAmount  Loan_Status\\n', '0       115.0      Default\\n', '1       130.0      Default\\n', '2       110.0  Not default\\n', '3        96.0      Default\\n', '4       230.0      Default']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>LoanAmount</th>\\n', '      <th>Loan_Status</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>115.0</td>\\n', '      <td>Default</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>130.0</td>\\n', '      <td>Default</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>110.0</td>\\n', '      <td>Not default</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>96.0</td>\\n', '      <td>Default</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>4</th>\\n', '      <td>230.0</td>\\n', '      <td>Default</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #80:\n",
      "Code:\n",
      "plotnine.options.figure_size = (8, 4.8)\n",
      "(\n",
      "    ggplot(\n",
      "        data = df_viz_5\n",
      "    )+\n",
      "    geom_density(\n",
      "        aes(\n",
      "            x = 'LoanAmount',\n",
      "            fill = 'Loan_Status'\n",
      "        ),\n",
      "        color = 'white',\n",
      "        alpha = 0.85\n",
      "    )+\n",
      "    labs(\n",
      "        title = 'The distribution of loan amount by loan status'\n",
      "    )+\n",
      "    scale_fill_manual(\n",
      "        name = 'Loan Status',\n",
      "        values = ['#981220','#80797c'],\n",
      "        labels = ['Default', 'Not Default']\n",
      "    )+\n",
      "    xlab(\n",
      "        'Loan amount'\n",
      "    )+\n",
      "    ylab(\n",
      "        'Density'\n",
      "    )+\n",
      "    theme_minimal()\n",
      ")\n",
      "\n",
      "Outputs:\n",
      "----------------------------------------\n",
      "\n",
      "Cell #84:\n",
      "Code:\n",
      "# Categorical columns\n",
      "cols_obj_train = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
      "print(cols_obj_train)\n",
      "\n",
      "Outputs:\n",
      "['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
      "\n",
      "['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #85:\n",
      "Code:\n",
      "# One-hot encoding\n",
      "df_concat = pd.get_dummies(data = df_concat, columns = cols_obj_train, drop_first = True)\n",
      "print('Dimension data: {} rows and {} columns'.format(len(df_concat), len(df_concat.columns)))\n",
      "df_concat.head()\n",
      "\n",
      "Outputs:\n",
      "Dimension data: 570 rows and 15 columns\n",
      "\n",
      "Dimension data: 570 rows and 15 columns\n",
      "\n",
      "['   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\\\\n', '0             4547                0.0       115.0             360.0   \\n', '1             5703                0.0       130.0             360.0   \\n', '2             4333             2451.0       110.0             360.0   \\n', '3             4695                0.0        96.0             360.0   \\n', '4             6700             1750.0       230.0             300.0   \\n', '\\n', '   Loan_Status  Gender_Male  Married_Yes  Dependents_1  Dependents_2  \\\\\\n', '0            1        False        False         False         False   \\n', '1            1         True         True         False         False   \\n', '2            0        False         True         False         False   \\n', '3            1         True         True         False         False   \\n', '4            1         True         True         False          True   \\n', '\\n', '   Dependents_3+  Education_Not Graduate  Self_Employed_Yes  \\\\\\n', '0          False                   False              False   \\n', '1           True                    True               True   \\n', '2          False                   False              False   \\n', '3          False                    True               True   \\n', '4          False                   False              False   \\n', '\\n', '   Credit_History_1.0  Property_Area_Semiurban  Property_Area_Urban  \\n', '0                True                     True                False  \\n', '1                True                    False                False  \\n', '2                True                    False                 True  \\n', '3                True                    False                 True  \\n', '4                True                     True                False  ']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>ApplicantIncome</th>\\n', '      <th>CoapplicantIncome</th>\\n', '      <th>LoanAmount</th>\\n', '      <th>Loan_Amount_Term</th>\\n', '      <th>Loan_Status</th>\\n', '      <th>Gender_Male</th>\\n', '      <th>Married_Yes</th>\\n', '      <th>Dependents_1</th>\\n', '      <th>Dependents_2</th>\\n', '      <th>Dependents_3+</th>\\n', '      <th>Education_Not Graduate</th>\\n', '      <th>Self_Employed_Yes</th>\\n', '      <th>Credit_History_1.0</th>\\n', '      <th>Property_Area_Semiurban</th>\\n', '      <th>Property_Area_Urban</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>4547</td>\\n', '      <td>0.0</td>\\n', '      <td>115.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>5703</td>\\n', '      <td>0.0</td>\\n', '      <td>130.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>4333</td>\\n', '      <td>2451.0</td>\\n', '      <td>110.0</td>\\n', '      <td>360.0</td>\\n', '      <td>0</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>4695</td>\\n', '      <td>0.0</td>\\n', '      <td>96.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>4</th>\\n', '      <td>6700</td>\\n', '      <td>1750.0</td>\\n', '      <td>230.0</td>\\n', '      <td>300.0</td>\\n', '      <td>1</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #87:\n",
      "Code:\n",
      "# Unique values of Loan_Status\n",
      "df_concat['Loan_Status'].value_counts()\n",
      "\n",
      "Outputs:\n",
      "['Loan_Status\\n', '1      330\\n', '0      134\\n', '999    106\\n', 'Name: count, dtype: int64']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #88:\n",
      "Code:\n",
      "# Training set\n",
      "df_train = df_concat[df_concat['Loan_Status'].isin([0, 1])].reset_index(drop = True)\n",
      "print('Dimension data: {} rows and {} columns'.format(len(df_train), len(df_train.columns)))\n",
      "df_train.head()\n",
      "\n",
      "Outputs:\n",
      "Dimension data: 464 rows and 15 columns\n",
      "\n",
      "Dimension data: 464 rows and 15 columns\n",
      "\n",
      "['   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\\\\n', '0             4547                0.0       115.0             360.0   \\n', '1             5703                0.0       130.0             360.0   \\n', '2             4333             2451.0       110.0             360.0   \\n', '3             4695                0.0        96.0             360.0   \\n', '4             6700             1750.0       230.0             300.0   \\n', '\\n', '   Loan_Status  Gender_Male  Married_Yes  Dependents_1  Dependents_2  \\\\\\n', '0            1        False        False         False         False   \\n', '1            1         True         True         False         False   \\n', '2            0        False         True         False         False   \\n', '3            1         True         True         False         False   \\n', '4            1         True         True         False          True   \\n', '\\n', '   Dependents_3+  Education_Not Graduate  Self_Employed_Yes  \\\\\\n', '0          False                   False              False   \\n', '1           True                    True               True   \\n', '2          False                   False              False   \\n', '3          False                    True               True   \\n', '4          False                   False              False   \\n', '\\n', '   Credit_History_1.0  Property_Area_Semiurban  Property_Area_Urban  \\n', '0                True                     True                False  \\n', '1                True                    False                False  \\n', '2                True                    False                 True  \\n', '3                True                    False                 True  \\n', '4                True                     True                False  ']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>ApplicantIncome</th>\\n', '      <th>CoapplicantIncome</th>\\n', '      <th>LoanAmount</th>\\n', '      <th>Loan_Amount_Term</th>\\n', '      <th>Loan_Status</th>\\n', '      <th>Gender_Male</th>\\n', '      <th>Married_Yes</th>\\n', '      <th>Dependents_1</th>\\n', '      <th>Dependents_2</th>\\n', '      <th>Dependents_3+</th>\\n', '      <th>Education_Not Graduate</th>\\n', '      <th>Self_Employed_Yes</th>\\n', '      <th>Credit_History_1.0</th>\\n', '      <th>Property_Area_Semiurban</th>\\n', '      <th>Property_Area_Urban</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>4547</td>\\n', '      <td>0.0</td>\\n', '      <td>115.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>5703</td>\\n', '      <td>0.0</td>\\n', '      <td>130.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>4333</td>\\n', '      <td>2451.0</td>\\n', '      <td>110.0</td>\\n', '      <td>360.0</td>\\n', '      <td>0</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>4695</td>\\n', '      <td>0.0</td>\\n', '      <td>96.0</td>\\n', '      <td>360.0</td>\\n', '      <td>1</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>4</th>\\n', '      <td>6700</td>\\n', '      <td>1750.0</td>\\n', '      <td>230.0</td>\\n', '      <td>300.0</td>\\n', '      <td>1</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #89:\n",
      "Code:\n",
      "# Testing set\n",
      "df_test = df_concat[df_concat['Loan_Status'].isin([999])].reset_index(drop = True)\n",
      "print('Data dimension: {} rows and {} columns'.format(len(df_test), len(df_test.columns)))\n",
      "df_test.head()\n",
      "\n",
      "Outputs:\n",
      "Data dimension: 106 rows and 15 columns\n",
      "\n",
      "Data dimension: 106 rows and 15 columns\n",
      "\n",
      "['   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\\\\n', '0             3748             1668.0       110.0             360.0   \\n', '1             4000             7750.0       290.0             360.0   \\n', '2             2625             6250.0       187.0             360.0   \\n', '3             3902             1666.0       109.0             360.0   \\n', '4             6096                0.0       218.0             360.0   \\n', '\\n', '   Loan_Status  Gender_Male  Married_Yes  Dependents_1  Dependents_2  \\\\\\n', '0          999         True        False         False         False   \\n', '1          999         True         True         False         False   \\n', '2          999         True         True         False         False   \\n', '3          999         True        False         False         False   \\n', '4          999         True         True         False         False   \\n', '\\n', '   Dependents_3+  Education_Not Graduate  Self_Employed_Yes  \\\\\\n', '0          False                    True              False   \\n', '1           True                   False              False   \\n', '2          False                   False              False   \\n', '3          False                    True              False   \\n', '4          False                    True              False   \\n', '\\n', '   Credit_History_1.0  Property_Area_Semiurban  Property_Area_Urban  \\n', '0                True                     True                False  \\n', '1                True                     True                False  \\n', '2                True                    False                False  \\n', '3                True                    False                False  \\n', '4               False                    False                False  ']\n",
      "['<div>\\n', '<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\\n', '<table border=\"1\" class=\"dataframe\">\\n', '  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>ApplicantIncome</th>\\n', '      <th>CoapplicantIncome</th>\\n', '      <th>LoanAmount</th>\\n', '      <th>Loan_Amount_Term</th>\\n', '      <th>Loan_Status</th>\\n', '      <th>Gender_Male</th>\\n', '      <th>Married_Yes</th>\\n', '      <th>Dependents_1</th>\\n', '      <th>Dependents_2</th>\\n', '      <th>Dependents_3+</th>\\n', '      <th>Education_Not Graduate</th>\\n', '      <th>Self_Employed_Yes</th>\\n', '      <th>Credit_History_1.0</th>\\n', '      <th>Property_Area_Semiurban</th>\\n', '      <th>Property_Area_Urban</th>\\n', '    </tr>\\n', '  </thead>\\n', '  <tbody>\\n', '    <tr>\\n', '      <th>0</th>\\n', '      <td>3748</td>\\n', '      <td>1668.0</td>\\n', '      <td>110.0</td>\\n', '      <td>360.0</td>\\n', '      <td>999</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>1</th>\\n', '      <td>4000</td>\\n', '      <td>7750.0</td>\\n', '      <td>290.0</td>\\n', '      <td>360.0</td>\\n', '      <td>999</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>2</th>\\n', '      <td>2625</td>\\n', '      <td>6250.0</td>\\n', '      <td>187.0</td>\\n', '      <td>360.0</td>\\n', '      <td>999</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>3</th>\\n', '      <td>3902</td>\\n', '      <td>1666.0</td>\\n', '      <td>109.0</td>\\n', '      <td>360.0</td>\\n', '      <td>999</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>4</th>\\n', '      <td>6096</td>\\n', '      <td>0.0</td>\\n', '      <td>218.0</td>\\n', '      <td>360.0</td>\\n', '      <td>999</td>\\n', '      <td>True</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>True</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '      <td>False</td>\\n', '    </tr>\\n', '  </tbody>\\n', '</table>\\n', '</div>']\n",
      "----------------------------------------\n",
      "\n",
      "Cell #90:\n",
      "Code:\n",
      "# Data partitioning >>> training set into training and validation\n",
      "df_train_final = df_train.reset_index(drop = True)\n",
      "X = df_train_final[df_train_final.columns[~df_train_final.columns.isin(['Loan_Status'])]]\n",
      "y = df_train_final['Loan_Status']\n",
      "\n",
      "# Training = 70% and validation = 30%\n",
      "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.3, random_state = 42)\n",
      "print('Data dimension of training set   :', X_train.shape)\n",
      "print('Data dimension of validation set :', X_test.shape)\n",
      "\n",
      "# Testing set\n",
      "X_test = df_test[df_test.columns[~df_test.columns.isin(['Loan_Status'])]]\n",
      "print('Data dimension of testing set    :', X_test.shape)\n",
      "\n",
      "Outputs:\n",
      "Data dimension of training set   : (324, 14)\n",
      "Data dimension of validation set : (140, 14)\n",
      "Data dimension of testing set    : (106, 14)\n",
      "\n",
      "Data dimension of training set   : (324, 14)\n",
      "Data dimension of validation set : (140, 14)\n",
      "Data dimension of testing set    : (106, 14)\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Cell #92:\n",
      "Code:\n",
      "testXGBoost model\n",
      "xgb_model = xgb.XGBClassifier(\n",
      "    objective = 'binary:logistic',\n",
      "    use_label_encoder = False\n",
      ")\n",
      "\n",
      "# Define parameter range \n",
      "params = {\n",
      "    'eta': np.arange(0.1, 0.26, 0.05),\n",
      "    'min_child_weight': np.arange(1, 5, 0.5).tolist(),\n",
      "    'gamma': [5],\n",
      "    'subsample': np.arange(0.5, 1.0, 0.11).tolist(),\n",
      "    'colsample_bytree': np.arange(0.5, 1.0, 0.11).tolist()\n",
      "}\n",
      "\n",
      "# Make a scorer from a performance metric or loss function\n",
      "scorers = {\n",
      "    'f1_score': make_scorer(f1_score),\n",
      "    'precision_score': make_scorer(precision_score),\n",
      "    'recall_score': make_scorer(recall_score),\n",
      "    'accuracy_score': make_scorer(accuracy_score)\n",
      "}\n",
      "\n",
      "# k-fold cross validation\n",
      "skf = KFold(n_splits = 10, shuffle = True)\n",
      "\n",
      "# Set up the grid search CV\n",
      "grid = GridSearchCV(\n",
      "    estimator = xgb_model,\n",
      "    param_grid = params,\n",
      "    scoring = scorers,\n",
      "    n_jobs = -1,\n",
      "    cv = skf.split(X_train, np.array(y_train)),\n",
      "    refit = 'accuracy_score'\n",
      ")\n",
      "\n",
      "# Fit the model\n",
      "grid.fit(X = X_train, y = y_train)\n",
      "\n",
      "# Best parameters\n",
      "grid.best_params_\n",
      "\n",
      "# Create a prediction of training \n",
      "predicted = grid.predict(X_test)\n",
      "\n",
      "# Model evaluation - training data\n",
      "accuracy_baseline = accuracy_score(predicted, np.array(y_test))\n",
      "recall_baseline = recall_score(predicted, np.array(y_test))\n",
      "precision_baseline = precision_score(predicted, np.array(y_test))\n",
      "f1_baseline = f1_score(predicted, np.array(y_test))\n",
      "\n",
      "print('Accuracy for baseline   :{}'.format(round(accuracy_baseline, 5)))\n",
      "print('Recall for baseline     :{}'.format(round(recall_baseline, 5)))\n",
      "print('Precision for baseline  :{}'.format(round(precision_baseline, 5)))\n",
      "print('F1 Score for baseline   :{}'.format(round(f1_baseline, 5)))\n",
      "\n",
      "\n",
      "Outputs:\n",
      "['\"  \\\\n# XGBoost model\\\\nxgb_model = xgb.XGBClassifier(\\\\n    objective = \\'binary:logistic\\',\\\\n    use_label_encoder = False\\\\n)\\\\n\\\\n# Define parameter range \\\\nparams = {\\\\n    \\'eta\\': np.arange(0.1, 0.26, 0.05),\\\\n    \\'min_child_weight\\': np.arange(1, 5, 0.5).tolist(),\\\\n    \\'gamma\\': [5],\\\\n    \\'subsample\\': np.arange(0.5, 1.0, 0.11).tolist(),\\\\n    \\'colsample_bytree\\': np.arange(0.5, 1.0, 0.11).tolist()\\\\n}\\\\n\\\\n# Make a scorer from a performance metric or loss function\\\\nscorers = {\\\\n    \\'f1_score\\': make_scorer(f1_score),\\\\n    \\'precision_score\\': make_scorer(precision_score),\\\\n    \\'recall_score\\': make_scorer(recall_score),\\\\n    \\'accuracy_score\\': make_scorer(accuracy_score)\\\\n}\\\\n\\\\n# k-fold cross validation\\\\nskf = KFold(n_splits = 10, shuffle = True)\\\\n\\\\n# Set up the grid search CV\\\\ngrid = GridSearchCV(\\\\n    estimator = xgb_model,\\\\n    param_grid = params,\\\\n    scoring = scorers,\\\\n    n_jobs = -1,\\\\n    cv = skf.split(X_train, np.array(y_train)),\\\\n    refit = \\'accuracy_score\\'\\\\n)\\\\n\\\\n# Fit the model\\\\ngrid.fit(X = X_train, y = y_train)\\\\n\\\\n# Best parameters\\\\ngrid.best_params_\\\\n\\\\n# Create a prediction of training \\\\npredicted = grid.predict(X_val)\\\\n\\\\n# Model evaluation - training data\\\\naccuracy_baseline = accuracy_score(predicted, np.array(y_val))\\\\nrecall_baseline = recall_score(predicted, np.array(y_val))\\\\nprecision_baseline = precision_score(predicted, np.array(y_val))\\\\nf1_baseline = f1_score(predicted, np.array(y_val))\\\\n\\\\nprint(\\'Accuracy for baseline   :{}\\'.format(round(accuracy_baseline, 5)))\\\\nprint(\\'Recall for baseline     :{}\\'.format(round(recall_baseline, 5)))\\\\nprint(\\'Precision for baseline  :{}\\'.format(round(precision_baseline, 5)))\\\\nprint(\\'F1 Score for baseline   :{}\\'.format(round(f1_baseline, 5)))\\\\n\\\\n\\\\n\"']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, cell in enumerate(notebook_contents['cells']):\n",
    "    if cell['cell_type'] == 'code' and cell.get('outputs'):\n",
    "        print(f\"\\nCell #{i+1}:\")\n",
    "        print(\"Code:\")\n",
    "        print(\"\".join(cell['source']))\n",
    "        print(\"\\nOutputs:\")\n",
    "        for output in cell['outputs']:\n",
    "            # Print text output (if any)\n",
    "            if 'text' in output:\n",
    "                print(\"\".join(output['text']))\n",
    "            # Print stream output\n",
    "            if output.get('output_type') == 'stream':\n",
    "                print(\"\".join(output.get('text', '')))\n",
    "            # Print execution result (display_data or execute_result)\n",
    "            if output.get('output_type') in ['execute_result', 'display_data']:\n",
    "                data = output.get('data', {})\n",
    "                # Print text/plain or html if present\n",
    "                if 'text/plain' in data:\n",
    "                    print(data['text/plain'])\n",
    "                if 'text/html' in data:\n",
    "                    print(data['text/html'])\n",
    "            # Print errors if any\n",
    "            if output.get('output_type') == 'error':\n",
    "                print(f\"Error: {output.get('ename')} - {output.get('evalue')}\")\n",
    "                print(\"Traceback:\")\n",
    "                print(\"\\n\".join(output.get('traceback', [])))\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0ef8bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell #11\n",
      "Code:\n",
      "# Data dimension\n",
      "print('Data dimension: {} rows and {} columns'.format(len(df_train), len(df_train.columns)))\n",
      "df_train.head()\n",
      "Output(s):\n",
      "Data dimension: 491 rows and 13 columns\n",
      "Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP002305  Female      No          0      Graduate            No   \n",
      "1  LP001715    Male     Yes         3+  Not Graduate           Yes   \n",
      "2  LP002086  Female     Yes          0      Graduate            No   \n",
      "3  LP001136    Male     Yes          0  Not Graduate           Yes   \n",
      "4  LP002529    Male     Yes          2      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             4547                0.0       115.0             360.0   \n",
      "1             5703                0.0       130.0             360.0   \n",
      "2             4333             2451.0       110.0             360.0   \n",
      "3             4695                0.0        96.0               NaN   \n",
      "4             6700             1750.0       230.0             300.0   \n",
      "\n",
      "   Credit_History Property_Area  Loan_Status  \n",
      "0             1.0     Semiurban            1  \n",
      "1             1.0         Rural            1  \n",
      "2             1.0         Urban            0  \n",
      "3             1.0         Urban            1  \n",
      "4             1.0     Semiurban            1\n",
      "------------------------------\n",
      "\n",
      "Cell #14\n",
      "Code:\n",
      "# Data dimension\n",
      "print('Data dimension: {} rows and {} columns'.format(len(df_test), len(df_test.columns)))\n",
      "df_test.head()\n",
      "Output(s):\n",
      "Data dimension: 123 rows and 12 columns\n",
      "Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001116   Male      No          0  Not Graduate            No   \n",
      "1  LP001488   Male     Yes         3+      Graduate            No   \n",
      "2  LP002138   Male     Yes          0      Graduate            No   \n",
      "3  LP002284   Male      No          0  Not Graduate            No   \n",
      "4  LP002328   Male     Yes          0  Not Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             3748             1668.0       110.0             360.0   \n",
      "1             4000             7750.0       290.0             360.0   \n",
      "2             2625             6250.0       187.0             360.0   \n",
      "3             3902             1666.0       109.0             360.0   \n",
      "4             6096                0.0       218.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area  \n",
      "0             1.0     Semiurban  \n",
      "1             1.0     Semiurban  \n",
      "2             1.0         Rural  \n",
      "3             1.0         Rural  \n",
      "4             0.0         Rural\n",
      "------------------------------\n",
      "\n",
      "Cell #19\n",
      "Code:\n",
      "# Data frame metadata\n",
      "df_train.info()\n",
      "Output(s):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 491 entries, 0 to 490\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            491 non-null    object \n",
      " 1   Gender             481 non-null    object \n",
      " 2   Married            490 non-null    object \n",
      " 3   Dependents         482 non-null    object \n",
      " 4   Education          491 non-null    object \n",
      " 5   Self_Employed      462 non-null    object \n",
      " 6   ApplicantIncome    491 non-null    int64  \n",
      " 7   CoapplicantIncome  491 non-null    float64\n",
      " 8   LoanAmount         475 non-null    float64\n",
      " 9   Loan_Amount_Term   478 non-null    float64\n",
      " 10  Credit_History     448 non-null    float64\n",
      " 11  Property_Area      491 non-null    object \n",
      " 12  Loan_Status        491 non-null    int64  \n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 50.0+ KB\n",
      "------------------------------\n",
      "\n",
      "Cell #20\n",
      "Code:\n",
      "# Change column types\n",
      "df_train = df_train.astype({'Credit_History': object, 'Loan_Status': int})\n",
      "df_train.select_dtypes(include = ['object']).dtypes\n",
      "Output(s):\n",
      "Loan_ID           object\n",
      "Gender            object\n",
      "Married           object\n",
      "Dependents        object\n",
      "Education         object\n",
      "Self_Employed     object\n",
      "Credit_History    object\n",
      "Property_Area     object\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "Cell #21\n",
      "Code:\n",
      "# Summary statistics of categorical columns\n",
      "for i in df_train.select_dtypes('object').columns:\n",
      "    print(df_train[i].value_counts(),'\\n')\n",
      "Output(s):\n",
      "Loan_ID\n",
      "LP002777    1\n",
      "LP002305    1\n",
      "LP001715    1\n",
      "LP002086    1\n",
      "LP001136    1\n",
      "           ..\n",
      "LP002379    1\n",
      "LP001011    1\n",
      "LP001508    1\n",
      "LP001112    1\n",
      "LP002130    1\n",
      "Name: count, Length: 491, dtype: int64 \n",
      "\n",
      "Gender\n",
      "Male      393\n",
      "Female     88\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Married\n",
      "Yes    324\n",
      "No     166\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Dependents\n",
      "0     276\n",
      "1      85\n",
      "2      78\n",
      "3+     43\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Education\n",
      "Graduate        388\n",
      "Not Graduate    103\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Self_Employed\n",
      "No     398\n",
      "Yes     64\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Credit_History\n",
      "1.0    380\n",
      "0.0     68\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Property_Area\n",
      "Semiurban    186\n",
      "Urban        155\n",
      "Rural        150\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Cell #23\n",
      "Code:\n",
      "# Check missing values\n",
      "df_train.isna().sum()\n",
      "Output(s):\n",
      "Loan_ID               0\n",
      "Gender               10\n",
      "Married               1\n",
      "Dependents            9\n",
      "Education             0\n",
      "Self_Employed        29\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           16\n",
      "Loan_Amount_Term     13\n",
      "Credit_History       43\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Cell #26\n",
      "Code:\n",
      "print('Number of missing dependents is about {} rows'.format(df_train['Dependents'].isna().sum()))\n",
      "Output(s):\n",
      "Number of missing dependents is about 9 rows\n",
      "------------------------------\n",
      "\n",
      "Cell #29\n",
      "Code:\n",
      "print('Number of missing Self_Employed is about {} rows'.format(df_train['Self_Employed'].isna().sum()))\n",
      "Output(s):\n",
      "Number of missing Self_Employed is about 29 rows\n",
      "------------------------------\n",
      "\n",
      "Cell #32\n",
      "Code:\n",
      "df_train[['Loan_Amount_Term', 'Loan_Status']].groupby('Loan_Status').describe()\n",
      "Output(s):\n",
      "Loan_Amount_Term                                             \\\n",
      "                       count        mean        std   min    25%    50%   \n",
      "Loan_Status                                                               \n",
      "0                      143.0  341.790210  73.018891  36.0  360.0  360.0   \n",
      "1                      335.0  341.086567  64.320411  12.0  360.0  360.0   \n",
      "\n",
      "                           \n",
      "               75%    max  \n",
      "Loan_Status                \n",
      "0            360.0  480.0  \n",
      "1            360.0  480.0\n",
      "------------------------------\n",
      "\n",
      "Cell #33\n",
      "Code:\n",
      "print('Percentile 20th: {}'.format(df_train['Loan_Amount_Term'].quantile(q = 0.2)))\n",
      "Output(s):\n",
      "Percentile 20th: 360.0\n",
      "------------------------------\n",
      "\n",
      "Cell #36\n",
      "Code:\n",
      "# Cross tabulation of credit history and loan status\n",
      "df_cred_hist = pd.crosstab(df_train['Credit_History'], df_train['Loan_Status'], margins = True).reset_index()\n",
      "# Remove index name\n",
      "df_cred_hist.columns.name = None\n",
      "# Remove last row for total column attribute\n",
      "df_cred_hist = df_cred_hist.drop([len(df_cred_hist) - 1], axis = 0)\n",
      "df_cred_hist.rename(columns = {'Credit_History':'Credit History', 0:'No', 1:'Yes'}, inplace = True)\n",
      "df_cred_hist\n",
      "Output(s):\n",
      "Credit History  No  Yes  All\n",
      "0            0.0  62    6   68\n",
      "1            1.0  74  306  380\n",
      "------------------------------\n",
      "\n",
      "Cell #37\n",
      "Code:\n",
      "# Slice the data frame based on loan status\n",
      "pos_cred_hist0 = df_train[(df_train['Credit_History'].isna()) & (df_train['Loan_Status'] == 0)]\n",
      "pos_cred_hist1 = df_train[(df_train['Credit_History'].isna()) & (df_train['Loan_Status'] == 1)]\n",
      "print('Number of rows with Loan_Status is No but Credit_History is NaN  : {}'.format(len(pos_cred_hist0)))\n",
      "print('Number of rows with Loan_Status is Yes but Credit_History is NaN : {}'.format(len(pos_cred_hist1)))\n",
      "Output(s):\n",
      "Number of rows with Loan_Status is No but Credit_History is NaN  : 12\n",
      "Number of rows with Loan_Status is Yes but Credit_History is NaN : 31\n",
      "------------------------------\n",
      "\n",
      "Cell #41\n",
      "Code:\n",
      "# Check missing value\n",
      "df_train.isna().sum()\n",
      "Output(s):\n",
      "Loan_ID              0\n",
      "Gender               0\n",
      "Married              0\n",
      "Dependents           0\n",
      "Education            0\n",
      "Self_Employed        0\n",
      "ApplicantIncome      0\n",
      "CoapplicantIncome    0\n",
      "LoanAmount           0\n",
      "Loan_Amount_Term     0\n",
      "Credit_History       0\n",
      "Property_Area        0\n",
      "Loan_Status          0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Cell #44\n",
      "Code:\n",
      "# Data frame metadata\n",
      "df_test.info()\n",
      "Output(s):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            123 non-null    object \n",
      " 1   Gender             120 non-null    object \n",
      " 2   Married            121 non-null    object \n",
      " 3   Dependents         117 non-null    object \n",
      " 4   Education          123 non-null    object \n",
      " 5   Self_Employed      120 non-null    object \n",
      " 6   ApplicantIncome    123 non-null    int64  \n",
      " 7   CoapplicantIncome  123 non-null    float64\n",
      " 8   LoanAmount         117 non-null    float64\n",
      " 9   Loan_Amount_Term   122 non-null    float64\n",
      " 10  Credit_History     116 non-null    float64\n",
      " 11  Property_Area      123 non-null    object \n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 11.7+ KB\n",
      "------------------------------\n",
      "\n",
      "Cell #45\n",
      "Code:\n",
      "# Change column types\n",
      "df_test = df_test.astype({'Credit_History': object})\n",
      "df_test.select_dtypes(include = ['object']).dtypes\n",
      "Output(s):\n",
      "Loan_ID           object\n",
      "Gender            object\n",
      "Married           object\n",
      "Dependents        object\n",
      "Education         object\n",
      "Self_Employed     object\n",
      "Credit_History    object\n",
      "Property_Area     object\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "Cell #46\n",
      "Code:\n",
      "# Summary statistics of categorical columns\n",
      "for i in df_test.select_dtypes('object').columns:\n",
      "    print(df_test[i].value_counts(),'\\n')\n",
      "Output(s):\n",
      "Loan_ID\n",
      "LP001116    1\n",
      "LP001488    1\n",
      "LP002138    1\n",
      "LP002284    1\n",
      "LP002328    1\n",
      "           ..\n",
      "LP002683    1\n",
      "LP002054    1\n",
      "LP002757    1\n",
      "LP002582    1\n",
      "LP001616    1\n",
      "Name: count, Length: 123, dtype: int64 \n",
      "\n",
      "Gender\n",
      "Male      96\n",
      "Female    24\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Married\n",
      "Yes    74\n",
      "No     47\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Dependents\n",
      "0     69\n",
      "2     23\n",
      "1     17\n",
      "3+     8\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Education\n",
      "Graduate        92\n",
      "Not Graduate    31\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Self_Employed\n",
      "No     102\n",
      "Yes     18\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Credit_History\n",
      "1.0    95\n",
      "0.0    21\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Property_Area\n",
      "Semiurban    47\n",
      "Urban        47\n",
      "Rural        29\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Cell #48\n",
      "Code:\n",
      "# Check missing values\n",
      "df_test.isna().sum()\n",
      "Output(s):\n",
      "Loan_ID              0\n",
      "Gender               3\n",
      "Married              2\n",
      "Dependents           6\n",
      "Education            0\n",
      "Self_Employed        3\n",
      "ApplicantIncome      0\n",
      "CoapplicantIncome    0\n",
      "LoanAmount           6\n",
      "Loan_Amount_Term     1\n",
      "Credit_History       7\n",
      "Property_Area        0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Cell #50\n",
      "Code:\n",
      "print('Number of missing values in Dependents is about {} rows'.format(df_test['Dependents'].isna().sum()))\n",
      "Output(s):\n",
      "Number of missing values in Dependents is about 6 rows\n",
      "------------------------------\n",
      "\n",
      "Cell #53\n",
      "Code:\n",
      "print('Number of missing values in Self_Employed is about {} rows'.format(df_test['Self_Employed'].isna().sum()))\n",
      "Output(s):\n",
      "Number of missing values in Self_Employed is about 3 rows\n",
      "------------------------------\n",
      "\n",
      "Cell #59\n",
      "Code:\n",
      "# Check missing values\n",
      "df_test.isna().sum()\n",
      "Output(s):\n",
      "Loan_ID              0\n",
      "Gender               0\n",
      "Married              0\n",
      "Dependents           0\n",
      "Education            0\n",
      "Self_Employed        0\n",
      "ApplicantIncome      0\n",
      "CoapplicantIncome    0\n",
      "LoanAmount           0\n",
      "Loan_Amount_Term     0\n",
      "Credit_History       0\n",
      "Property_Area        0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Cell #63\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_1\n",
      "Output(s):\n",
      "Loan_Status  Total\n",
      "0  Not default    134\n",
      "1      Default    330\n",
      "------------------------------\n",
      "\n",
      "Cell #64\n",
      "Code:\n",
      "# Figure size\n",
      "plt.figure(figsize = (6.4,4.8))\n",
      "\n",
      "# Customize colors and other settings\n",
      "colors = ['#80797c','#981220']\n",
      "\n",
      "# Explode 1st slice\n",
      "explode = (0.1, 0)\n",
      "\n",
      "# Create a pie chart\n",
      "plt.pie(\n",
      "    x = 'Total',\n",
      "    labels = 'Loan_Status',\n",
      "    data = df_viz_1,\n",
      "    explode = explode,\n",
      "    colors = colors,\n",
      "    autopct = '%1.1f%%',\n",
      "    shadow = False,\n",
      "    startangle = 140\n",
      ")\n",
      "\n",
      "# Title and axis\n",
      "plt.title('Number of customers by loan status', fontsize = 18)\n",
      "plt.axis('equal')\n",
      "plt.show()\n",
      "Output(s):\n",
      "<Figure size 640x480 with 1 Axes>\n",
      "------------------------------\n",
      "\n",
      "Cell #67\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_2\n",
      "Output(s):\n",
      "Loan_Status Dependents  Total\n",
      "0  Not default          0     77\n",
      "1  Not default          1     30\n",
      "2  Not default          2     13\n",
      "3  Not default         3+     14\n",
      "4      Default          0    191\n",
      "5      Default          1     52\n",
      "6      Default          2     62\n",
      "7      Default         3+     25\n",
      "------------------------------\n",
      "\n",
      "Cell #68\n",
      "Code:\n",
      "plotnine.options.figure_size = (8, 4.8)\n",
      "(\n",
      "    ggplot(\n",
      "        data = df_viz_2\n",
      "    )+\n",
      "    geom_bar(\n",
      "        aes(\n",
      "            x = 'Dependents',\n",
      "            y = 'Total',\n",
      "            fill = 'Loan_Status'\n",
      "        ),\n",
      "        stat = 'identity',\n",
      "        position = 'fill',\n",
      "        width = 0.5\n",
      "    )+\n",
      "    labs(\n",
      "        title = 'The composition of loan status by the dependents',\n",
      "        fill = 'Loan status'\n",
      "    )+\n",
      "    xlab(\n",
      "        'Dependents'\n",
      "    )+\n",
      "    ylab(\n",
      "        'Frequency'\n",
      "    )+\n",
      "    scale_x_discrete(\n",
      "        limits = ['0', '1', '2', '3+']\n",
      "    )+\n",
      "    scale_fill_manual(\n",
      "        values = ['#981220','#80797c'],\n",
      "        labels = ['Default', 'Not Default']\n",
      "    )+\n",
      "    theme_minimal()\n",
      ")\n",
      "Output(s):\n",
      "------------------------------\n",
      "\n",
      "Cell #71\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_3\n",
      "Output(s):\n",
      "Loan_Status     Education  Total\n",
      "0  Not default      Graduate    101\n",
      "1  Not default  Not Graduate     33\n",
      "2      Default      Graduate    266\n",
      "3      Default  Not Graduate     64\n",
      "------------------------------\n",
      "\n",
      "Cell #72\n",
      "Code:\n",
      "plotnine.options.figure_size = (8, 4.8)\n",
      "(\n",
      "    ggplot(\n",
      "        data = df_viz_3\n",
      "    )+\n",
      "    geom_bar(\n",
      "        aes(\n",
      "            x = 'Education',\n",
      "            y = 'Total',\n",
      "            fill = 'Loan_Status'\n",
      "        ),\n",
      "        stat = 'identity',\n",
      "        position = 'fill',\n",
      "        width = 0.5\n",
      "    )+\n",
      "    labs(\n",
      "        title = 'The composition of loan status by the education',\n",
      "        fill = 'Loan status'\n",
      "    )+\n",
      "    xlab(\n",
      "        'Educations'\n",
      "    )+\n",
      "    ylab(\n",
      "        'Frequency'\n",
      "    )+\n",
      "    scale_x_discrete(\n",
      "        limits = ['Graduate', 'Not Graduate']\n",
      "    )+\n",
      "    scale_fill_manual(\n",
      "        values = ['#981220','#80797c'],\n",
      "        labels = ['Default', 'Not Default']\n",
      "    )+\n",
      "    theme_minimal()\n",
      ")\n",
      "Output(s):\n",
      "------------------------------\n",
      "\n",
      "Cell #75\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_4.head()\n",
      "Output(s):\n",
      "ApplicantIncome  Loan_Status\n",
      "0             4547      Default\n",
      "1             5703      Default\n",
      "2             4333  Not default\n",
      "3             4695      Default\n",
      "4             6700      Default\n",
      "------------------------------\n",
      "\n",
      "Cell #76\n",
      "Code:\n",
      "plotnine.options.figure_size = (8, 4.8)\n",
      "(\n",
      "    ggplot(\n",
      "        data = df_viz_4\n",
      "    )+\n",
      "    geom_density(\n",
      "        aes(\n",
      "            x = 'ApplicantIncome',\n",
      "            fill = 'Loan_Status'\n",
      "        ),\n",
      "        color = 'white',\n",
      "        alpha = 0.85\n",
      "    )+\n",
      "    labs(\n",
      "        title = 'The distribution of applicant incomes by loan status'\n",
      "    )+\n",
      "    scale_fill_manual(\n",
      "        name = 'Loan Status',\n",
      "        values = ['#981220','#80797c'],\n",
      "        labels = ['Default', 'Not Default']\n",
      "    )+\n",
      "    xlab(\n",
      "        'Applicant income'\n",
      "    )+\n",
      "    ylab(\n",
      "        'Density'\n",
      "    )+\n",
      "    theme_minimal()\n",
      ")\n",
      "Output(s):\n",
      "------------------------------\n",
      "\n",
      "Cell #79\n",
      "Code:\n",
      "# Show the data\n",
      "df_viz_5.head()\n",
      "Output(s):\n",
      "LoanAmount  Loan_Status\n",
      "0       115.0      Default\n",
      "1       130.0      Default\n",
      "2       110.0  Not default\n",
      "3        96.0      Default\n",
      "4       230.0      Default\n",
      "------------------------------\n",
      "\n",
      "Cell #80\n",
      "Code:\n",
      "plotnine.options.figure_size = (8, 4.8)\n",
      "(\n",
      "    ggplot(\n",
      "        data = df_viz_5\n",
      "    )+\n",
      "    geom_density(\n",
      "        aes(\n",
      "            x = 'LoanAmount',\n",
      "            fill = 'Loan_Status'\n",
      "        ),\n",
      "        color = 'white',\n",
      "        alpha = 0.85\n",
      "    )+\n",
      "    labs(\n",
      "        title = 'The distribution of loan amount by loan status'\n",
      "    )+\n",
      "    scale_fill_manual(\n",
      "        name = 'Loan Status',\n",
      "        values = ['#981220','#80797c'],\n",
      "        labels = ['Default', 'Not Default']\n",
      "    )+\n",
      "    xlab(\n",
      "        'Loan amount'\n",
      "    )+\n",
      "    ylab(\n",
      "        'Density'\n",
      "    )+\n",
      "    theme_minimal()\n",
      ")\n",
      "Output(s):\n",
      "------------------------------\n",
      "\n",
      "Cell #84\n",
      "Code:\n",
      "# Categorical columns\n",
      "cols_obj_train = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
      "print(cols_obj_train)\n",
      "Output(s):\n",
      "['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
      "------------------------------\n",
      "\n",
      "Cell #85\n",
      "Code:\n",
      "# One-hot encoding\n",
      "df_concat = pd.get_dummies(data = df_concat, columns = cols_obj_train, drop_first = True)\n",
      "print('Dimension data: {} rows and {} columns'.format(len(df_concat), len(df_concat.columns)))\n",
      "df_concat.head()\n",
      "Output(s):\n",
      "Dimension data: 570 rows and 15 columns\n",
      "ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             4547                0.0       115.0             360.0   \n",
      "1             5703                0.0       130.0             360.0   \n",
      "2             4333             2451.0       110.0             360.0   \n",
      "3             4695                0.0        96.0             360.0   \n",
      "4             6700             1750.0       230.0             300.0   \n",
      "\n",
      "   Loan_Status  Gender_Male  Married_Yes  Dependents_1  Dependents_2  \\\n",
      "0            1        False        False         False         False   \n",
      "1            1         True         True         False         False   \n",
      "2            0        False         True         False         False   \n",
      "3            1         True         True         False         False   \n",
      "4            1         True         True         False          True   \n",
      "\n",
      "   Dependents_3+  Education_Not Graduate  Self_Employed_Yes  \\\n",
      "0          False                   False              False   \n",
      "1           True                    True               True   \n",
      "2          False                   False              False   \n",
      "3          False                    True               True   \n",
      "4          False                   False              False   \n",
      "\n",
      "   Credit_History_1.0  Property_Area_Semiurban  Property_Area_Urban  \n",
      "0                True                     True                False  \n",
      "1                True                    False                False  \n",
      "2                True                    False                 True  \n",
      "3                True                    False                 True  \n",
      "4                True                     True                False\n",
      "------------------------------\n",
      "\n",
      "Cell #87\n",
      "Code:\n",
      "# Unique values of Loan_Status\n",
      "df_concat['Loan_Status'].value_counts()\n",
      "Output(s):\n",
      "Loan_Status\n",
      "1      330\n",
      "0      134\n",
      "999    106\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Cell #88\n",
      "Code:\n",
      "# Training set\n",
      "df_train = df_concat[df_concat['Loan_Status'].isin([0, 1])].reset_index(drop = True)\n",
      "print('Dimension data: {} rows and {} columns'.format(len(df_train), len(df_train.columns)))\n",
      "df_train.head()\n",
      "Output(s):\n",
      "Dimension data: 464 rows and 15 columns\n",
      "ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             4547                0.0       115.0             360.0   \n",
      "1             5703                0.0       130.0             360.0   \n",
      "2             4333             2451.0       110.0             360.0   \n",
      "3             4695                0.0        96.0             360.0   \n",
      "4             6700             1750.0       230.0             300.0   \n",
      "\n",
      "   Loan_Status  Gender_Male  Married_Yes  Dependents_1  Dependents_2  \\\n",
      "0            1        False        False         False         False   \n",
      "1            1         True         True         False         False   \n",
      "2            0        False         True         False         False   \n",
      "3            1         True         True         False         False   \n",
      "4            1         True         True         False          True   \n",
      "\n",
      "   Dependents_3+  Education_Not Graduate  Self_Employed_Yes  \\\n",
      "0          False                   False              False   \n",
      "1           True                    True               True   \n",
      "2          False                   False              False   \n",
      "3          False                    True               True   \n",
      "4          False                   False              False   \n",
      "\n",
      "   Credit_History_1.0  Property_Area_Semiurban  Property_Area_Urban  \n",
      "0                True                     True                False  \n",
      "1                True                    False                False  \n",
      "2                True                    False                 True  \n",
      "3                True                    False                 True  \n",
      "4                True                     True                False\n",
      "------------------------------\n",
      "\n",
      "Cell #89\n",
      "Code:\n",
      "# Testing set\n",
      "df_test = df_concat[df_concat['Loan_Status'].isin([999])].reset_index(drop = True)\n",
      "print('Data dimension: {} rows and {} columns'.format(len(df_test), len(df_test.columns)))\n",
      "df_test.head()\n",
      "Output(s):\n",
      "Data dimension: 106 rows and 15 columns\n",
      "ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             3748             1668.0       110.0             360.0   \n",
      "1             4000             7750.0       290.0             360.0   \n",
      "2             2625             6250.0       187.0             360.0   \n",
      "3             3902             1666.0       109.0             360.0   \n",
      "4             6096                0.0       218.0             360.0   \n",
      "\n",
      "   Loan_Status  Gender_Male  Married_Yes  Dependents_1  Dependents_2  \\\n",
      "0          999         True        False         False         False   \n",
      "1          999         True         True         False         False   \n",
      "2          999         True         True         False         False   \n",
      "3          999         True        False         False         False   \n",
      "4          999         True         True         False         False   \n",
      "\n",
      "   Dependents_3+  Education_Not Graduate  Self_Employed_Yes  \\\n",
      "0          False                    True              False   \n",
      "1           True                   False              False   \n",
      "2          False                   False              False   \n",
      "3          False                    True              False   \n",
      "4          False                    True              False   \n",
      "\n",
      "   Credit_History_1.0  Property_Area_Semiurban  Property_Area_Urban  \n",
      "0                True                     True                False  \n",
      "1                True                     True                False  \n",
      "2                True                    False                False  \n",
      "3                True                    False                False  \n",
      "4               False                    False                False\n",
      "------------------------------\n",
      "\n",
      "Cell #90\n",
      "Code:\n",
      "# Data partitioning >>> training set into training and validation\n",
      "df_train_final = df_train.reset_index(drop = True)\n",
      "X = df_train_final[df_train_final.columns[~df_train_final.columns.isin(['Loan_Status'])]]\n",
      "y = df_train_final['Loan_Status']\n",
      "\n",
      "# Training = 70% and validation = 30%\n",
      "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.3, random_state = 42)\n",
      "print('Data dimension of training set   :', X_train.shape)\n",
      "print('Data dimension of validation set :', X_test.shape)\n",
      "\n",
      "# Testing set\n",
      "X_test = df_test[df_test.columns[~df_test.columns.isin(['Loan_Status'])]]\n",
      "print('Data dimension of testing set    :', X_test.shape)\n",
      "Output(s):\n",
      "Data dimension of training set   : (324, 14)\n",
      "Data dimension of validation set : (140, 14)\n",
      "Data dimension of testing set    : (106, 14)\n",
      "------------------------------\n",
      "\n",
      "Cell #92\n",
      "Code:\n",
      "testXGBoost model\n",
      "xgb_model = xgb.XGBClassifier(\n",
      "    objective = 'binary:logistic',\n",
      "    use_label_encoder = False\n",
      ")\n",
      "\n",
      "# Define parameter range \n",
      "params = {\n",
      "    'eta': np.arange(0.1, 0.26, 0.05),\n",
      "    'min_child_weight': np.arange(1, 5, 0.5).tolist(),\n",
      "    'gamma': [5],\n",
      "    'subsample': np.arange(0.5, 1.0, 0.11).tolist(),\n",
      "    'colsample_bytree': np.arange(0.5, 1.0, 0.11).tolist()\n",
      "}\n",
      "\n",
      "# Make a scorer from a performance metric or loss function\n",
      "scorers = {\n",
      "    'f1_score': make_scorer(f1_score),\n",
      "    'precision_score': make_scorer(precision_score),\n",
      "    'recall_score': make_scorer(recall_score),\n",
      "    'accuracy_score': make_scorer(accuracy_score)\n",
      "}\n",
      "\n",
      "# k-fold cross validation\n",
      "skf = KFold(n_splits = 10, shuffle = True)\n",
      "\n",
      "# Set up the grid search CV\n",
      "grid = GridSearchCV(\n",
      "    estimator = xgb_model,\n",
      "    param_grid = params,\n",
      "    scoring = scorers,\n",
      "    n_jobs = -1,\n",
      "    cv = skf.split(X_train, np.array(y_train)),\n",
      "    refit = 'accuracy_score'\n",
      ")\n",
      "\n",
      "# Fit the model\n",
      "grid.fit(X = X_train, y = y_train)\n",
      "\n",
      "# Best parameters\n",
      "grid.best_params_\n",
      "\n",
      "# Create a prediction of training \n",
      "predicted = grid.predict(X_test)\n",
      "\n",
      "# Model evaluation - training data\n",
      "accuracy_baseline = accuracy_score(predicted, np.array(y_test))\n",
      "recall_baseline = recall_score(predicted, np.array(y_test))\n",
      "precision_baseline = precision_score(predicted, np.array(y_test))\n",
      "f1_baseline = f1_score(predicted, np.array(y_test))\n",
      "\n",
      "print('Accuracy for baseline   :{}'.format(round(accuracy_baseline, 5)))\n",
      "print('Recall for baseline     :{}'.format(round(recall_baseline, 5)))\n",
      "print('Precision for baseline  :{}'.format(round(precision_baseline, 5)))\n",
      "print('F1 Score for baseline   :{}'.format(round(f1_baseline, 5)))\n",
      "Output(s):\n",
      "\"  \\n# XGBoost model\\nxgb_model = xgb.XGBClassifier(\\n    objective = 'binary:logistic',\\n    use_label_encoder = False\\n)\\n\\n# Define parameter range \\nparams = {\\n    'eta': np.arange(0.1, 0.26, 0.05),\\n    'min_child_weight': np.arange(1, 5, 0.5).tolist(),\\n    'gamma': [5],\\n    'subsample': np.arange(0.5, 1.0, 0.11).tolist(),\\n    'colsample_bytree': np.arange(0.5, 1.0, 0.11).tolist()\\n}\\n\\n# Make a scorer from a performance metric or loss function\\nscorers = {\\n    'f1_score': make_scorer(f1_score),\\n    'precision_score': make_scorer(precision_score),\\n    'recall_score': make_scorer(recall_score),\\n    'accuracy_score': make_scorer(accuracy_score)\\n}\\n\\n# k-fold cross validation\\nskf = KFold(n_splits = 10, shuffle = True)\\n\\n# Set up the grid search CV\\ngrid = GridSearchCV(\\n    estimator = xgb_model,\\n    param_grid = params,\\n    scoring = scorers,\\n    n_jobs = -1,\\n    cv = skf.split(X_train, np.array(y_train)),\\n    refit = 'accuracy_score'\\n)\\n\\n# Fit the model\\ngrid.fit(X = X_train, y = y_train)\\n\\n# Best parameters\\ngrid.best_params_\\n\\n# Create a prediction of training \\npredicted = grid.predict(X_val)\\n\\n# Model evaluation - training data\\naccuracy_baseline = accuracy_score(predicted, np.array(y_val))\\nrecall_baseline = recall_score(predicted, np.array(y_val))\\nprecision_baseline = precision_score(predicted, np.array(y_val))\\nf1_baseline = f1_score(predicted, np.array(y_val))\\n\\nprint('Accuracy for baseline   :{}'.format(round(accuracy_baseline, 5)))\\nprint('Recall for baseline     :{}'.format(round(recall_baseline, 5)))\\nprint('Precision for baseline  :{}'.format(round(precision_baseline, 5)))\\nprint('F1 Score for baseline   :{}'.format(round(f1_baseline, 5)))\\n\\n\\n\"\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_cells_text = \"\"\n",
    "\n",
    "for i, cell in enumerate(notebook_contents['cells']):\n",
    "    if cell['cell_type'] == 'code' and cell.get('outputs'):\n",
    "        # Add cell number and code\n",
    "        all_cells_text += f\"\\nCell #{i+1}\\n\"\n",
    "        all_cells_text += \"Code:\\n\"\n",
    "        all_cells_text += \"\".join(cell['source']).strip() + \"\\n\"\n",
    "        all_cells_text += \"Output(s):\\n\"\n",
    "        # Add outputs\n",
    "        for output in cell['outputs']:\n",
    "            output_text = \"\"\n",
    "            if output.get('output_type') == 'stream':\n",
    "                text = output.get('text', '')\n",
    "                if isinstance(text, list):\n",
    "                    text = \"\".join(text)\n",
    "                output_text += text.strip()\n",
    "            elif output.get('output_type') in ['execute_result', 'display_data']:\n",
    "                data = output.get('data', {})\n",
    "                text = data.get('text/plain', '')\n",
    "                if isinstance(text, list):\n",
    "                    text = \"\".join(text)\n",
    "                output_text += text.strip()\n",
    "            # Skipping errors\n",
    "            if output_text:\n",
    "                all_cells_text += output_text + \"\\n\"\n",
    "        all_cells_text += \"-\" * 30 + \"\\n\"\n",
    "\n",
    "# Optional: remove leading/trailing whitespace\n",
    "all_cells_text = all_cells_text.strip()\n",
    "\n",
    "# Print or use as needed\n",
    "print(all_cells_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
