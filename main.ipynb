{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e18532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import nbformat\n",
    "import streamlit as st\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Load White Paper  (PDF)  \n",
    "2. Vectors Embeddings - Text and tables; later include images\n",
    "3. Chroma db\n",
    "4. Retrival - (Accuracy)\n",
    "5. Generation - \n",
    "    Validation-\n",
    "        Data sources - List all sources and metadata\n",
    "        Features - detect any change in features\n",
    "        Changes in Transformation steps\n",
    "        Model Details \n",
    "        Hyperparameter\n",
    "        List of Validation Metrics and resepctive scores\n",
    "        Compare Validation scores of white paper with model's validation scores\n",
    "        Brief of comparision of scores\n",
    "\n",
    "        List and Track of critical metrics - these should not be lower than mentioned (in white paper)\n",
    "\n",
    "6. Respective scores for tracked metrics (confidence on generation)\n",
    "7. If required update prompt and go back to step 4 and reiterate step 4 and 5. reason (geneation have \n",
    "   heiger confidence )\n",
    "8. Outout should be in structured format (This will be input for summary block with affitional 2 inputs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1358c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Local\\Temp\\ipykernel_26552\\3010324141.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\",\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\",  \n",
    "                 temperature=0,\n",
    "                 openai_api_key= openai_api_key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f30bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_notebook(file_path):\n",
    "    \"\"\"Read .ipynb notebook and extract content.\"\"\"\n",
    "    nb = nbformat.read(file_path, as_version=4)\n",
    "    content = []\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            content.append(\"## Markdown Cell:\\n\" + cell.source)\n",
    "        elif cell.cell_type == 'code':\n",
    "            content.append(\"## Code Cell:\\n```python\\n\" + cell.source + \"\\n```\")\n",
    "    return \"\\n\\n\".join(content)\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"Reads the content of a file.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def extract_functionalities_from_code(notebook_content):\n",
    "\n",
    "    \"\"\"Uses LLM to extract functionalities from Python code.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert Python code reviewer. Here is a Jupyter notebook:\n",
    "    {notebook_content}\n",
    "\n",
    "    The following is a Jupyter notebook content (code and markdown). \n",
    "    Please extract the following:\n",
    "    Analyze the notebook and answer:\n",
    "\n",
    "    1. List of features used in the model.\n",
    "    2. Name/type of ML model used, only name of model\n",
    "    3. Accuracy metrics (e.g., accuracy, F1, precision, recall, AUC, etc.), only metrics name. \n",
    "    4. What is the purpose of this notebook?\n",
    "    5. What are the main operations and their results?\n",
    "    6. Are there any errors or anomalies in outputs?\n",
    "    7. What conclusions can be drawn from the outputs?\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([SystemMessage(content=\"You are a helpful assistant.\"), HumanMessage(content=prompt)])\n",
    "\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "def extract_functionalities_from_whitepaper(whitepaper_text):\n",
    "    \"\"\"Uses LLM to extract functionalities from whitepaper.\"\"\"\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"You are a product analyst.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Here is the whitepaper or product requirement document:\n",
    "\n",
    "        {whitepaper_text}\n",
    "\n",
    "        List all functionalities or features the whitepaper mentions. Use bullet points.\n",
    "        \"\"\")\n",
    "            ]\n",
    "    return llm(prompt).content.strip()\n",
    "\n",
    "\n",
    "def compare_functionalities(whitepaper_funcs, code_funcs):\n",
    "    \"\"\"Compares two sets of functionalities using the LLM.\"\"\"\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"You are a software QA expert.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Whitepaper Functionalities:\n",
    "        {whitepaper_funcs}\n",
    "\n",
    "        Code Functionalities:\n",
    "        {code_funcs}\n",
    "        Extract validation metrics from code funcs eg, precision, recall and other validation are in output cell.\n",
    "        Compare the two lists and identify which functionalities from the whitepape, if functionality is implemented in code but not available in white paper, print: white paper is not updated please update the document. and show details of each section \n",
    "        listmissing sections like feature and if model varies according to white paper and same for validation metrics.\n",
    "        compare validation scores : Compare scores of code function with white paper.\n",
    "        Also compare critical validation metrics: make sure critical metrics of code should be grater then white paper critical metrics\n",
    "        if thereis no changhe in metrics of docuemt and code_funcs: keep output 'white paper is updated please proceed to next steps. no other information is required'  \n",
    "        \n",
    "        \"\"\")\n",
    "            ]\n",
    "    return llm(prompt).content.strip()\n",
    "\n",
    "\n",
    "def read_notebook_with_outputs(file_path):\n",
    "    \"\"\"Read .ipynb notebook and include both code and output.\"\"\"\n",
    "    nb = nbformat.read(file_path, as_version=4)\n",
    "    cells_content = []\n",
    "\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            cells_content.append(f\"## Markdown Cell:\\n{cell.source}\")\n",
    "        elif cell.cell_type == 'code':\n",
    "            code = f\"## Code Cell:\\n```python\\n{cell.source}\\n```\"\n",
    "            outputs = []\n",
    "\n",
    "            for output in cell.get(\"outputs\", []):\n",
    "                if output.output_type == \"stream\":\n",
    "                    outputs.append(f\"Output (stream):\\n{output.text}\")\n",
    "                elif output.output_type == \"execute_result\":\n",
    "                    # Display the result of the cell (e.g., print(2+2))\n",
    "                    result = output.get(\"data\", {}).get(\"text/plain\", \"\")\n",
    "                    outputs.append(f\"Output (execute_result):\\n{result}\")\n",
    "                elif output.output_type == \"error\":\n",
    "                    outputs.append(\"Error:\\n\" + \"\\n\".join(output.get(\"traceback\", [])))\n",
    "\n",
    "            full_output = \"\\n\".join(outputs)\n",
    "            if full_output:\n",
    "                code += f\"\\n\\n### Output:\\n```\\n{full_output}\\n```\"\n",
    "            cells_content.append(code)\n",
    "\n",
    "    return \"\\n\\n\".join(cells_content)\n",
    "\n",
    "def read_notebook(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return nbformat.read(f, as_version=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcfe8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Functionality Coverage Checker\", layout=\"wide\")\n",
    "    \n",
    "    st.title(\"🧠 AI Feature Mapping Validator\")\n",
    "    st.subheader(\"Compare functionalities between a Whitepaper and its Codebase\")\n",
    "\n",
    "    uploaded_whitepaper = st.file_uploader(\"📄 Upload Whitepaper File\", type=[\"txt\", \"md\", \"pdf\"])\n",
    "    uploaded_code = st.file_uploader(\"💻 Upload Code File\", type=[\"py\", \"txt\", \"ipynb\"])\n",
    "\n",
    "    if uploaded_whitepaper and uploaded_code:\n",
    "        if st.button(\"Click to Process Files\"):\n",
    "            # Read whitepaper content\n",
    "            whitepaper = uploaded_whitepaper.read().decode(\"utf-8\")\n",
    "\n",
    "            # Handle .ipynb or other code files\n",
    "            if uploaded_code.name.endswith(\".ipynb\"):\n",
    "                # Write the raw content to a temp file\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=\".ipynb\", mode='wb') as tmp_file:\n",
    "                    tmp_file.write(uploaded_code.read())\n",
    "                    temp_file_path = tmp_file.name\n",
    "\n",
    "                # notebook_contents = read_notebook(temp_file_path)\n",
    "                notebook_contents = read_notebook_with_outputs(temp_file_path)\n",
    "                code_funcs = extract_functionalities_from_code(notebook_contents)\n",
    "            else:\n",
    "                code = uploaded_code.read().decode(\"utf-8\")\n",
    "                code_funcs = extract_functionalities_from_code(code)\n",
    "\n",
    "            whitepaper_funcs = extract_functionalities_from_whitepaper(whitepaper)\n",
    "\n",
    "            st.markdown(\"### ⚖️ Comparing Functionalities\")\n",
    "            missing_funcs = compare_functionalities(whitepaper_funcs, code_funcs)\n",
    "            st.markdown(missing_funcs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c540a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f7a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1b071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25394f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a51519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "from openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3769bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "            \"Summary/Objective of white paper \",\n",
    "            \"Features mentioned\",\n",
    "            \"Preprocessing steps and data transformation steps\",\n",
    "            \"Model selected for classification\",\n",
    "            \"Training and resting methodology\",\n",
    "            \"List of Hyper parameters and respective values\",\n",
    "            \"What are list of validation scores and the performance scores?\",\n",
    "            \"Ethical considerations\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b706715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryFun(query, embedding_model,collection):\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    l_docs = []\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=5)\n",
    "    for doc in results[\"documents\"][0]:\n",
    "        l_docs.append(doc)\n",
    "        # print(\"🔎 Match:\", l_docs.append(doc))\n",
    "    return l_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee4fc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5e06b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "\n",
    "# Reconnect to the persisted ChromaDB directory\n",
    "path = \"./chroma_openai1\"  # must be the same path used earlier\n",
    "collection_name = \"whitepaper_embeddings\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84349973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the persistent client\n",
    "chroma_client = PersistentClient(path=path)\n",
    "\n",
    "# Step 2: Access the existing collection\n",
    "collection = chroma_client.get_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7484104f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs: ['chunk-0', 'chunk-1', 'chunk-2', 'chunk-3', 'chunk-4', 'chunk-5', 'chunk-6', 'chunk-7', 'chunk-8', 'chunk-9', 'chunk-10', 'chunk-11', 'chunk-12', 'chunk-13', 'chunk-14', 'chunk-15', 'chunk-16', 'chunk-17', 'chunk-18', 'chunk-19', 'chunk-20', 'chunk-21', 'chunk-22', 'chunk-23', 'chunk-24', 'chunk-25', 'chunk-26', 'chunk-27', 'chunk-28', 'chunk-29', 'chunk-30', 'chunk-31', 'chunk-32', 'chunk-33']\n",
      "Documents: ['--- Page 1 ---\\n\\n\\n--- Page 2 ---\\n\\n\\n--- Page 3 ---\\n\\n\\n--- Page 4 ---\\n\\n\\n--- Page 5 ---\\n\\n\\n--- Page 6 ---\\n\\n\\n--- Page 7 ---\\n\\n\\n--- Page 8 ---\\n\\n\\n--- Page 9 ---\\n\\n\\n--- Page 10 ---\\n\\n\\n--- Page 11 ---\\n\\n\\n--- Page 12 ---\\n\\n\\n--- Page 13 ---\\n\\n\\n--- Page 14 ---\\n\\n\\n--- Page 15 ---', \"Our system is designed to provide a high-level overview of an applicant's\\ncreditworthiness, offering a data-driven, objective, and transparent decision-making tool.\\nBy integrating advanced machine learning techniques, our model achieves superior\\npredictive accuracy compared to traditional methods. It significantly reduces the time\\nfrom application to decision, minimizes the risk of default, and ensures a consistent, fair\\nevaluation process. This strategic asset not only enhances operational efficiency but\\nalso provides a competitive advantage by enabling faster, more confident lending\\ndecisions.\\n2. Introduction\\nThe process of loan approval is a cornerstone of the financial industry. It involves\\nevaluating a multitude of factors to determine an applicant's creditworthiness and ability\\nto repay a loan. Historically, this process has been labor-intensive, relying on credit\\nofficers to manually review application forms, financial statements, and credit reports.\"]\n",
      "Metadata: [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "data = collection.get()\n",
    "\n",
    "# Optional: View details\n",
    "print(\"IDs:\", data['ids'])\n",
    "print(\"Documents:\", data['documents'][:2])  # print only first 2 docs\n",
    "print(\"Metadata:\", data.get('metadatas'))  # only if metadata was stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211070c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c057c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = chroma_client.list_collections()\n",
    "for col in collections:\n",
    "    print(col.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ce62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    l_docs = queryFun(query=query,embedding_model=embedding_model,collection =collection)\n",
    "    list_pdf_docs.append(l_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a48c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
